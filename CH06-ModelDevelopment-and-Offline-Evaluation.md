# CH06.  Model Development and Offline Evaluation  
(모델 개발과 오프라인 평가)


- 모델 개발은 반복 프로세스.    
- 반복이 끝날 때마다 모델 성능을 비교   

- 반복 단계 결과물의 성능이 이전 반복 단계와 비교해서 프로덕션 환경에 얼마나  
  적합한지를 평가   


### <6.1 모델 개발과 훈련>     

- 주어진 문제에 대해 다양한 ML 모델 평가하는 방법, 모델 앙상블 생성,    
  실험 추척좌 버전 관리, 분산 훈련 ->(심화)오토ML,즉 문제에 가장 적합한 모델을    
  선택하는 기법


#### 6.1.1 머신러닝 모델 평가    

- 시간과 연산 능력은 한정 -> 어떤 모델을 선택할지 전략적으로 접근 필요   

- 딥러닝이 프로덕션 환경에서 점점 많이 사용되는 추세     
  but, 기존 ML 알고리즘 또한 제자리를 굳건히 지키고 있음    
  많은 추천 시스템이 여전히 협업 필터링과 행렬 분해 기법에 의존ing.   

  그래디언트 부스트 트리 같은 트리 기반 알고리즘은 여전히 레이턴시    
  요구사항이 까다로운 다양한 분류 작업 지원     


- 신경망이 배포된 애플리케이션에도 여전히 고전적인 ML 알고리즘이 함께 사용    
  example, 신경망과 의사 결정 트리는 앙상블로써 함께 사용   
  또, k-mean 클러스터링 모델을 사용해서 신경망에 입력할 피처 추출    
  
  이와 반대로, BERT나 GPT-3과 같이 사전 훈련된 신경망을 사용해   
  로지스틱 회귀 모델에 입력할 임베딩을 생성하기도 함    



- 문제에 대한 모델을 선택할 떄 가용한 모델 전체가 아니라 문제에 일반저긍로 적합한    
  모델 집합에 집중    

  example, 유해한 트윗을 탐지하는 시스템을 개발한다고 가정했을 때,    
  이는 텍스트 분류 문제로, 주어진 텍스트가 유해한지 판별하는 문제이다.    
  텍스트 분류 용도로 흔히 사용하는 모델은 나이브 베이즈, 로지스틱 회귀, 순환 신경망,    
  트랜스포머 기반(BERT, GPT와 그 변종) 등이 있음     


  이상 거래 탐지 시스템을 개발한다고 가정하면, 전형적인 이상탐지 문제는 탐지하고자    
  하는 이상치를 k-nn, 아이솔레이션 포레스트, 클러스터링, 신경망 등 다양한 알고리즘이 사용   

  - 주어진 문제 사용할 모델을 선택하려면 일반적인 ML 작업 유형과 이를 해결하기 위한   
    접근법에 대한 지식이 필요     
   
exmpale, 단순 로지스틱 회구는 복잡한 신겨망보다는 정확도가 낮지만, 시작할 때 필요한 레이블      
데이터 개수가 적고 훈련 속도가 빠르고 배포 과정이 쉬우며 특정 예측값이 나오는 이유를 설명하기 쉬움    

<모델 선택 시 활용할 수 있는 팁>    

- 최첨단만 추종하는 함정에 빠지지 않기   

- 가장 단순한 모델부터 시작하기    
  (zen of Python : 단순함이 복잡한 것보다 낫다)   
  - 단순한 모델 배포(deploy) 쉬움   
  - 모델을 이해하고 디버깅하기 더 쉬움   
  - 가장 단순한 모델 복잡한 모델의 비교 대상으로서 베이스라인(baseline)의 역할 수행   

- 모델을 선택할 때 사람의 편항을 주의하기   
  => 모델 아키텍처 성능은 평가 맥락, 작업, 훈련 데이터, 테스트 데이터, 하이퍼파라미터 등에 크게 좌우되어    
  특정 모델 아키텍처가 다른 아키텍처보다 낫다고 단언하기 어려움    

- 현재 성과와 미래 성과를 비교 평가    

  현재 최적인 모델이 두 달 후에도 최적은 아닐 수 있음   
  학습 곡선으로 데이터가 늘어남에 따라 모델 성능이 어떻게 변할지 가늠 가능   
  모델  학습 곡선은 사용하는 훈련 샘플 개수에 따른 모델 성능의 플롯     
  (ex: 훈련 손실, 훈련 정확도, 검증 정확도)   

  ![img](img/fig6-1.png)


- 트레이드오프(trade-off) 평가하기    
  -> ML 시스템의 성능을 결정하는 요소 중 무엇이 더 중요한지 이해함   
  연산량 요구사항과 정확도 간의 트레이드 오프 케이스에서 복잡한 모델은 정확도가 높지만   
  추론시 사용 가능한 레이턴시로 예측값을 생성하려면 CPU 대신 GPU를 사용하는 등   
  강력한 시스템이 필요함   
  해석 가능성과 성능 간의 트레이드오프 또한 관심 대상임     
  복잡한 모델은 성능은 좋지만 결과를 해석하기 어려움     


- 모델의 가정을 이해하기
  
  - 예측 가정(Prediction assumption)
    입력 X에서 출력 Y를 예측하는 것이 목표인 모델은 X를 기반으로 Y를 에측할 수 있다 가정  

  - IID(Independent and Identically Distributed)   
    신경망은 각각의 데이터 포인트가 독립적이고 분포가 동일하다고 가정   
    (모든 데이터 포인트가 동일한 결합 분포에서 독립적으로 추출됐다는 의미)    

  - 매끄러움(Smoothness)   
    모든 머신러닝 지도 학습 방법은 입력을 출력으로 변환하는 함수 집합으로 가정함.    
    유사한 입력값은 유사한 출력값으로 변환됨    
    입력 X가 출력 Y를 생성한다면 X에 가까운 입력값은 비례적으로 Y의 가까운 출력값을 생성함     

  - 계산가능성(Tractability)    
    X는 입력이고 Z는 X의 잠재 표현이라고 할 때 생성 모델은 확률(Z|X)를 계산할 수 있다고 가정    

  - 경계(Boundaries)   
    선형 분류기는 결정 경계가 선형이라고 가정    

  - 조건부 독립(Conditional independence)    
    나이브 베이즈 분류기는 정해진 클래스에 대해 속성값들이 상호 독립이라고 가정함    

  - 정규 분포(Normally distributed).  
    많은 통계적 방법론은 데이터가 정규분포를 따른다고 가정함    




  
#### 6.1.2 앙상블(Ensemble)    

- 문제에 어떤 ML 솔루션을 사용할지 처음 고민하는 단계에서는 모델 단 하나만 포함하는 시스템으로 시작하면 좋음     

- 단일 모델을 개발한 뒤에는 성능을 지속적으로 향상하기 위한 방법을 고민하게 되는데, 한 가지 방법은   
  개별 모델이 아니라 여러 모델의 앙상블을 이용해 예측하는 것임   

- 앙상블 내의 각 모델을 기본 학습기(base learner)라고 하는데, 이메일의 스팸 여부를 예측하는  
  작업을 예로 들면 세 가지 모델에서 최종 예측은 세 모델의 다수결 투표로 결정함    

- 앙상블 모델은 배포가 복잡하고 유지 관리가 어려워 프로덕션 환경에서는 선호되지 않지만     
  광고 클릭률 예측 처럼 성능이 조금만 향상되도 금전적 이득이 큰 경우 자주 사용함     

- 앙상블을 구성할 때는 일반적으로 유형이 서로 상당히 다른 모델을 선택함     
  => 예를 들어 트랜스포머 모델 하나, 순환 신경망 하나, 그래디언트 부스트 트리 하나로 구성할 수 있음    


- 앙상블을 만드는 방법은 배깅, 부스팅, 스태킹 등 세가지    
  여러 조사 연구 논문에 따르면 리샘플링과 부스팅, 배깅 같은 앙상블 기법은 성능 항샹 외에도    
  불균형 데이터세 문제 완화에 도움    



- ***배깅(Boostrap Aggregating)***
  ML 알고리즘의 훈련 안정성과 정확도를 모두 개선하도록 설계되어, 분산을 줄이고 과적합 방지   
  데이터셋이 주어진 전체 데이터셋으로 하나의 분류기를 훈련하는 대신 복원 추출을 수행해 여러 데이터셋 생성   
  => 여기서의 각 데이터셋 부트스트랩     
  각 부트스트랩으로 분류 또는 회귀 모델 훈련  
  복원 추출이라 각 부트스트랩은 서로 독립적으로 생성됨   
  분류 문제에서는 모든 모델의 다수결 투표(vote)로 최종 예측값 결정   
  회귀 문제에서 최종 예측값은 모든 모델 예측값의 평균  

![img](img/fig6-3.png)


  배깅은 일반적으로 불안정성이 높은 기법의 성능을 개선하는데,     
  신경망/분류 및 회귀 트리/선형 회귀의 변수 하위 집합의 선택에 사용     
  반면에 k-최근접 이웃처럼 안정적인 기법의 성능은 다소 저하될 수 있음   

  랜덤 포레스트는 배깅의 일종으로 배깅에 피처의 무작위성을 더해 구성한 의사 결정 트리의 모음으로,    
  각 트리는 무작위로 정한 피처 하위 집합에서 사용할 피처를 선택함    



- ***부스팅***
  부스팅은 약한 학습기를 강한 학습기로 바꾸는 반복 학습 앙상블 알고리즘   
  앙상블을 구성하는 각 학습기는 동일한 샘플 집합으로 학습하지만 반복마다 각 샘플에 가중치를 다르게 줘서,    
  나중에 더해지는 약한 학습기는 이전의 약한 학습기들이 잘못 분류한 데이터 포인트에 집중함    


![img](img/fig6-4.png)


  [1] 원래 데이터셋으로 첫 번째 약한 분류기 훈련.  
  [2] 샘플마다 첫 번째 분류기에서 얼마나 잘 분류되는지에 따라 가중치 부여. 잘못 분류된 샘플에는 더 높은 가중치 부여  
  [3] 가중치가 부여된 데이터셋으로 두 번째 분류기 훈련. 앙상블을은 첫 번재와 두 번째 분류기로 구성  
  [4] 샘플마다 앙상블에서 얼마나 잘 분류되는지에 따라 가중치 재부여   
  [5] 가중치가 재부여된 데이터셋으로 세 번째 분류기 훈련. 앙상블에서 세번째 분류기 추가  
  [6] 필요한 만큼 반복.    
  [7] 최종적올 기존 분류기의 가중치 조합으로 강한 분류기 구성. 분류기의 훈련 오차가 적을 수록 가중치 높음.  


  부스팅 알고리즘의 예는 약한 결정 트리에서 예측모델을 생성하는 그래디언트 부스팅(GBM(gradient boosting model)  
  으로, 다른 부스팅 방법과 마찬가지로 단계적으로 모델을 구축하고 임의의 미분 가능한 손실 함수를 최적하하면서   
  모델을 일반화함   

  GBM의 변형 알고리즘인 XGBoost는 ML 대회에서 다수의 우승 팀에게 선택받았음   
  분류, 랭킹부터 힉스 보손(Higgs Boson)의 발견에 이르기까지 광범위한 작업에 사용   
  최근에는 병렬 학습을 지원하는 분산형 그래디언트 부스팅 프레임워크인 LightGBM으로   
  대규모 데이터셋에 대한 훈련 작업을 더 빠르게 함    

- ***스태킹***   
  스태킹은 훈련 데이터로 기본 학습기를 훈련하고, 기본 학습기의 출력을 결합해     
  최종 에측을 수행하는 메타 학습기를 만듦. 메타 학습기는 단슨한 휴리스틱일 수 있음   
  모든 기본 학습기에 대해 다수결 투표 (뿐류 작업) 혹은 평균 투표(회귀 작업)을 수행함   
  기본 학습기로는 로지스틱 회귀 모델이나 선형 회귀 모델 등 서로 다른 종류의 모델 집합을 사용할 수 있음   
  (앙상블 생성 방법을 보다 자세히 학습하려면 캐글의 전설적인 팀 MLWave의 멋진 앙상블 가이드 문서 참조)    
  https://oreil.ly/Nu666   

![img](img/fig6-5.png)