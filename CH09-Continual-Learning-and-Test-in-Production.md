# CH09 연속 학습과 프로덕션 테스트(Continual Learning and Test in Production)

- 연속 학습은 주로 인프라 문제    
- 모델을 얼마나 재훈련 해야하는지, 원하는 만큼 자주 업데이트 하도록    
  인프라를 설정한 후에 재훈련 빈도 고려해야 함     

- 고정 테스트 세트에서 평가하는 것은 충분 x.    
  어렵지만 꼭 필요한 개념인 프로덕션 테스트를 다룸    

- 이 프로세스는 프로덕션에서 라이브 데이터로 시스템을 테스트하는 방법으로,    
  업데이트된 모델이 파괴적인 결과 없이 제대로 작동하는지 확인     

## 9.1 연속 학습     

- '연속학습' 모델이 프로덕션에서 들어오는 모든 샘플로 스스로 업데이트하는    
  훈련 패러다임 생각 -> 하지만 실제로 그렇게 하는 기업 거의 없음     

- 첫쩨, 모델이 신경망이라면 모든 입력 샘플로 학습하면    
  파괴적 망각(catastrophic. forgetting)에 취약해짐     
  파괴적 망각은 신경망이 새로운 정보를 학습할 때  이전에 학습한 정보를    
  갑자기 잊어버리는 경향     

- 둘째, 훈련 비용이 더 많이 듦. 오늘날 백엔드는 대부분 배치 처리를 위해 설계    
  샘플을 하나씩 처리하면 연산 성능이 크게 낭비되고 데이터 병렬 처리를 활용할 수 없음    

- 프로덕션에서 연속 학습을 사용하는 회사는 모델을 마이크로 배치로 업데이트   
  Ex] 데이너 포인트 512개마다 혹은 1024개마다 기존 모델을 업데이트함.    
  각 마이크로 배치의 최적 샘플 개수는 작업에 따라 다름    

- 업데이트된 모델은 평가가 완료될 떄까지 배포 x. 즉, 기존 모델을 직접 변경해선 안됨    
  대신 기존 모델의 복제본을 생성해 신규 데이터로 업데이트하고,    
  업데이트된 복제본이 더 낫다고  판명할 때만 기존 모델을 업데이트된 복제본으로 교체     

  기존 모델을 챔피언(champion) 모델, 업데이트된 복제 모델을 도전자(challenger)   
  실제로 회사에는 동시에 여러 도전자 모델이 있으며 실패한 모델이 있으며    
  실패한 도전자 모델을 다루는 과정은 단순 폐기보다 훨씬 정교    

[fig9-1](img/fig9-1.png)


- 대부분의 회사에서 모델을 자주 업데이트 할 필요가 없다고 주장(이유 2가지)    
  
- 첫째, 재훈련 일정이 타당할 만큼 충분한 트래픽, 즉 충분한 신규 데이터가 없기 때문    

- 둘째, 모델 성능이 그렇게 빨리 떨어지지 않기 때문(필자는 이 의견에 동의)   
  
- 재훈련 일정을 일주일에서 하루로 변경해도 수익이 나지 않고 더많은 오버헤드가 발생한다면   
  모델을 자주 업데이트 할 필요 없음    


### 9.1.1 무상태 재훈련 vs 상태 유지 훈련    

- 연속학습은 재훈련 빈도가 아니라 모델 재훈련 방식과 관련    
  
- 대부분 무상태 재훈련(stateless retraining)을 수행해 모델이 매번 처음부터 훈련   

- 연속 학습은 상태 유지 훈련(stateful training)을 허용함을 의미하며    
  모델은 신규 데이터로  훈련을 지속    

  상태 유지 훈련은 미세 조정(fine-tunning) 혹은   
  중복 훈련(incremental training)이라고 도 함    

[fig9-2](img/fig9-2.png)


- 상태 유지 훈련을 사용하면 더 적은 데이터로 모델을 업데이트    
  모델을 처음부터 훈련하려면 동일한 모델을 미세 조정할 때보다 데이터가 훨씬 많이 필요    

  ex] 모델을 처음부터 다시 훈련하려면 지난 3개월 데이터를 모두 사용해야 할 수 있지만    
  이제 체크포인트에서 모델을 미세 조정하려면 마지막 날 데이터만 사용하면 됨    

- 그럽허브는 상태 유지 훈련을 하면 모델이 더 빠르게 수렴하며   
  필요한 연산 비용도 훨씬 적음을 발견   

  일일 무상태 재훈련에서 일일 상태 유지훈련으로 전환하자   
  훈련 연산 비용이 45분의 1로 감소,  구매율(purchase-through rate) 20% 증가    

- 상태 유지 훈련을 하면 데이터를 완전히 저장하는 일을 피할 수 있음    
  기존 무상태 재훈련에서 데이터 샘플을 모델을 여러번 반복 훈련하는 동안 재사용됨   
  그런데 데이터 저장이 항상 가능하지 않음(특히 개인정보보호 요구사항이 엄격한 경우)   


- 상태 유지 훈련 패러다임에서는 신규 데이터로만 훈련되므로    
  한 데이터 샘플은 훈련에 한 번만 사용   
  즉, 데이터를 영구 스토리지에 저장할 필요 없이 모델 훈련이 이루어지므로 
  개인 정보 보호에 대한 우려 많이 덜음    


- 상태 유지 훈련이 대량의 데이터로 처음부터 훈련하지 않는다는 의미가 아님    
  즉, 신규 데이터로 미세 조정만 수행하지는 않음      
  
  상태 유지 훈련을 가장 성공적으로 적용한 기업에서도 종종 모델을 교정하기 위해    
  대량의 데이터로 처음부터 모델을 훈련함.     
  혹은 상태 유지 훈련과 병행해 모델을 처음부터 훈련하고 파라미터 서버    
  같은 기술을 사용해 업데이트된 두 모델을 결합하기도 함.    

- 인프라가 무상태 재훈련과 상태 유지 훈련을 모두 허용하도록 설정되면    
  훈련 빈도는 쉽게 조정 가능    


- 모델에 신규 피처나 다른 레이어를 추가하고 싶다면 어떻게 작동 ?   
  두가지 모델 업데이트 유형을 구별해야 함    

  - 모델 반복(Model iteration).  
  : 기존 모델 아키텍처에 새로운 피처가 추가되거나 모델 아키텍처가 변경됨     

  - 데이터 반복(Data iteration).  
  : 모델 아키텍쳐와 피처는 동일하게 유지되지만 신규 데이터로 모델을 갱신    


- 오늘날 상태 유지 훈련은 대부분 데이터 반복에 적용   
  
- 모델 아키텍처를 변경하거나 새로운 피처를 추가하려면 모델을 처음부터 훈련해야 함   
  
- 모델 반복의 경우 구글의 'knowledg transfer'와 OpenAI 'model surgery' 같은   
  기법을 사용해 처음부터 훈련을 우회할수 있다는 연구 결과 존재    

  OpenAI에서는 surgery는 선택 프로세스 후에 훈련된 가중치를 한 네트워크에서    
  다른 네트워크로 전송    
  이 포르세슨느 모델에서 어던 부분이 변경되지 않으면 어떤 부분을 다시 초기화해야 하는지   
  결정하기 위함    


***애매한 용어***

- '온라인 학습'이라는 용어 대신 '연속 학습(continual learning)' 용어 사용    

- continuous learning 대신 continual learning 이라는 용어 사용

- continuous learning은 모델이 들어오는 샘플로 지속적으로 학습하는 체제를 의미   

- continual learning에서는 학습이 일련의 배치 혹은 마이크로 배치로 수행   

- cotinuous learning은 때때로 ML의 지속적인 제공(continous delivery(CD))을   
  지정하는데 사용되는데,     
  CD는 continual learning과 밀절합 관련이 있음    

  continuous learning은 기업이 ML 모델의 반복 주기를 가속화하는 데 도움이 됨   
  다만 차이점은 이러한 의미로 사용될떄   
  continuous learning은 CD를 위한 파이프라인 설정에 대한 DevOps 관점   
  continual learning 은 ML 관점에서 사용   



### 9.1.2 연속 학습의 필요성     




```
test code
```
