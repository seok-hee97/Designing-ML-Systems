# CH09 연속 학습과 프로덕션 테스트(Continual Learning and Test in Production)

- 연속 학습은 주로 인프라 문제    
- 모델을 얼마나 재훈련 해야하는지, 원하는 만큼 자주 업데이트 하도록    
  인프라를 설정한 후에 재훈련 빈도 고려해야 함     

- 고정 테스트 세트에서 평가하는 것은 충분 x.    
  어렵지만 꼭 필요한 개념인 프로덕션 테스트를 다룸    

- 이 프로세스는 프로덕션에서 라이브 데이터로 시스템을 테스트하는 방법으로,    
  업데이트된 모델이 파괴적인 결과 없이 제대로 작동하는지 확인     

## 9.1 연속 학습     

- '연속학습' 모델이 프로덕션에서 들어오는 모든 샘플로 스스로 업데이트하는    
  훈련 패러다임 생각 -> 하지만 실제로 그렇게 하는 기업 거의 없음     

- 첫쩨, 모델이 신경망이라면 모든 입력 샘플로 학습하면    
  파괴적 망각(catastrophic. forgetting)에 취약해짐     
  파괴적 망각은 신경망이 새로운 정보를 학습할 때  이전에 학습한 정보를    
  갑자기 잊어버리는 경향     

- 둘째, 훈련 비용이 더 많이 듦. 오늘날 백엔드는 대부분 배치 처리를 위해 설계    
  샘플을 하나씩 처리하면 연산 성능이 크게 낭비되고 데이터 병렬 처리를 활용할 수 없음    

- 프로덕션에서 연속 학습을 사용하는 회사는 모델을 마이크로 배치로 업데이트   
  Ex] 데이너 포인트 512개마다 혹은 1024개마다 기존 모델을 업데이트함.    
  각 마이크로 배치의 최적 샘플 개수는 작업에 따라 다름    

- 업데이트된 모델은 평가가 완료될 떄까지 배포 x. 즉, 기존 모델을 직접 변경해선 안됨    
  대신 기존 모델의 복제본을 생성해 신규 데이터로 업데이트하고,    
  업데이트된 복제본이 더 낫다고  판명할 때만 기존 모델을 업데이트된 복제본으로 교체     

  기존 모델을 챔피언(champion) 모델, 업데이트된 복제 모델을 도전자(challenger)   
  실제로 회사에는 동시에 여러 도전자 모델이 있으며 실패한 모델이 있으며    
  실패한 도전자 모델을 다루는 과정은 단순 폐기보다 훨씬 정교    

![fig9-1](img/fig9-1.png)


- 대부분의 회사에서 모델을 자주 업데이트 할 필요가 없다고 주장(이유 2가지)    
  
- 첫째, 재훈련 일정이 타당할 만큼 충분한 트래픽, 즉 충분한 신규 데이터가 없기 때문    

- 둘째, 모델 성능이 그렇게 빨리 떨어지지 않기 때문(필자는 이 의견에 동의)   
  
- 재훈련 일정을 일주일에서 하루로 변경해도 수익이 나지 않고 더많은 오버헤드가 발생한다면   
  모델을 자주 업데이트 할 필요 없음    


### 9.1.1 무상태 재훈련 vs 상태 유지 훈련    

- 연속학습은 재훈련 빈도가 아니라 모델 재훈련 방식과 관련    
  
- 대부분 무상태 재훈련(stateless retraining)을 수행해 모델이 매번 처음부터 훈련   

- 연속 학습은 상태 유지 훈련(stateful training)을 허용함을 의미하며    
  모델은 신규 데이터로  훈련을 지속    

  상태 유지 훈련은 미세 조정(fine-tunning) 혹은   
  중복 훈련(incremental training)이라고 도 함    

![fig9-2](img/fig9-2.png)


- 상태 유지 훈련을 사용하면 더 적은 데이터로 모델을 업데이트    
  모델을 처음부터 훈련하려면 동일한 모델을 미세 조정할 때보다 데이터가 훨씬 많이 필요    

  ex] 모델을 처음부터 다시 훈련하려면 지난 3개월 데이터를 모두 사용해야 할 수 있지만    
  이제 체크포인트에서 모델을 미세 조정하려면 마지막 날 데이터만 사용하면 됨    

- 그럽허브는 상태 유지 훈련을 하면 모델이 더 빠르게 수렴하며   
  필요한 연산 비용도 훨씬 적음을 발견   

  일일 무상태 재훈련에서 일일 상태 유지훈련으로 전환하자   
  훈련 연산 비용이 45분의 1로 감소,  구매율(purchase-through rate) 20% 증가    

- 상태 유지 훈련을 하면 데이터를 완전히 저장하는 일을 피할 수 있음    
  기존 무상태 재훈련에서 데이터 샘플을 모델을 여러번 반복 훈련하는 동안 재사용됨   
  그런데 데이터 저장이 항상 가능하지 않음(특히 개인정보보호 요구사항이 엄격한 경우)   


- 상태 유지 훈련 패러다임에서는 신규 데이터로만 훈련되므로    
  한 데이터 샘플은 훈련에 한 번만 사용   
  즉, 데이터를 영구 스토리지에 저장할 필요 없이 모델 훈련이 이루어지므로 
  개인 정보 보호에 대한 우려 많이 덜음    


- 상태 유지 훈련이 대량의 데이터로 처음부터 훈련하지 않는다는 의미가 아님    
  즉, 신규 데이터로 미세 조정만 수행하지는 않음      
  
  상태 유지 훈련을 가장 성공적으로 적용한 기업에서도 종종 모델을 교정하기 위해    
  대량의 데이터로 처음부터 모델을 훈련함.     
  혹은 상태 유지 훈련과 병행해 모델을 처음부터 훈련하고 파라미터 서버    
  같은 기술을 사용해 업데이트된 두 모델을 결합하기도 함.    

- 인프라가 무상태 재훈련과 상태 유지 훈련을 모두 허용하도록 설정되면    
  훈련 빈도는 쉽게 조정 가능    


- 모델에 신규 피처나 다른 레이어를 추가하고 싶다면 어떻게 작동 ?   
  두가지 모델 업데이트 유형을 구별해야 함    

  - 모델 반복(Model iteration).  
  : 기존 모델 아키텍처에 새로운 피처가 추가되거나 모델 아키텍처가 변경됨     

  - 데이터 반복(Data iteration).  
  : 모델 아키텍쳐와 피처는 동일하게 유지되지만 신규 데이터로 모델을 갱신    


- 오늘날 상태 유지 훈련은 대부분 데이터 반복에 적용   
  
- 모델 아키텍처를 변경하거나 새로운 피처를 추가하려면 모델을 처음부터 훈련해야 함   
  
- 모델 반복의 경우 구글의 'knowledg transfer'와 OpenAI 'model surgery' 같은   
  기법을 사용해 처음부터 훈련을 우회할수 있다는 연구 결과 존재    

  OpenAI에서는 surgery는 선택 프로세스 후에 훈련된 가중치를 한 네트워크에서    
  다른 네트워크로 전송    
  이 포르세슨느 모델에서 어던 부분이 변경되지 않으면 어떤 부분을 다시 초기화해야 하는지   
  결정하기 위함    


***애매한 용어***

- '온라인 학습'이라는 용어 대신 '연속 학습(continual learning)' 용어 사용    

- continuous learning 대신 continual learning 이라는 용어 사용

- continuous learning은 모델이 들어오는 샘플로 지속적으로 학습하는 체제를 의미   

- continual learning에서는 학습이 일련의 배치 혹은 마이크로 배치로 수행   

- cotinuous learning은 때때로 ML의 지속적인 제공(continous delivery(CD))을   
  지정하는데 사용되는데,     
  CD는 continual learning과 밀절합 관련이 있음    

  continuous learning은 기업이 ML 모델의 반복 주기를 가속화하는 데 도움이 됨   
  다만 차이점은 이러한 의미로 사용될떄   
  continuous learning은 CD를 위한 파이프라인 설정에 대한 DevOps 관점   
  continual learning 은 ML 관점에서 사용   



### 9.1.2 연속 학습의 필요성     

- 연속학습은 모델을 업데이트하고 변경 사항을 원하는 만큼 빠르게 배포할 수 있도록   
  인프라를 설정하는 것    

1. 데이터 분포 시프트, 특히 갑자기 발생하는 시프트에 대처하는 일.
   
   Ex] 리프트 같은 승차 공유 서비스의 가격 결정 모델을 구축한다고 가정할때,    
   특정 지역은 역사적으로 목요일 저녁에 운행 수가 적고,    
   따라서 모델이 낮은 운행가격을 예측해 운전자자 운행을 선호 x.    
   그런데 이번 목요일은 저녁에 동네에 큰 행사가 있어 운행 수요가 급증.   
   모델이 이러한 변화에 빠르게 대응할 수 있다면 높은 운행 가격을 예측하고    
   더 많은 운전자를 동원하겠지만,    
   반대로 충분히 빠르게 대응할 수 없다면 탑승하는 승차하기 위해    
   오랫동안 기다려야하고 이는 부정적인 사용자 경험을 유발.       
   심지어 탑승자가 경쟁사 앱을 전환해 수익을 잃을 가능성도 존재.     
 

2. 희귀한 사건(rare event)에 적응하는 것.

  Ex]전자 상거래 웹사이트에서 일한다고 가정.   
  블랙 프라이 데이는 1년에 단 한번 열리는 중요한 쇼핑 이벤트에 해당.    
  하지만 이번 블랙 프라이데이 기간의 고객 행동을 정확하게 예측할 수 있도록    
  모델에 대한 과거 데이터를 충분히 수집할 방법은 없음.     
  성능을 향상시키리면 모델이 하루 종일 신규 데이터로 훈련해야 함.   
  2019년 알리바바는 스트리림 처리 프레임워크인 아파치 플링크의 개발을     
  주도하는 데이터 아티산 팀을 1억 300만 달러에 인수했고,    
  팀은 플링크를 ML 유스 케이스에 적응시키는데 도움을 줌.    
  주요 유스케이스는 미국의 블랙 프라이 데이와 유사한    
  중국 쇼핑 이벤트인 광군제에 더 좋은 추천을 수행하는 것.   
 

3. 오늘날 ML 프로덕션의 주요 난제인 지속 콜드 스타트(continuous cold start)    
   문제에도 도움이 됨.     

   콜드 스타트 문제는 모델이 과거 데이터 없이 신규 사용자를 예측해야 할 때 발생.    
   Ex] 추천 시스템에서 사용자에게 추천을 하기 위해서는 과거 이력을 알아야 함.    
   그러나 해당 사용자가 신규 사용자라면 기록이 없으므로 현재 가장 인기 있는    
   영화같이 일반적인 추천 리스트를 생성해야 함.    

   지속 코드 스타트는 콜드 스타트 문제를 일반화 한 것으로,     
   신규 사용자뿐 아니라 기존 사용자에게도 발생.    
   Ex]기존 사용자가 노트북에서 휴대 전화로 전환하는데 휴대전화에서 동작이   
   노트북에서와 달라서 발생하기도 함.
   사용자가 로그인하지 않아도 발생.    
   뉴스사이트는 대부분 로그인하지 않아도 기사를 읽을 수 있음.  

   Ex] 어떤 사용자가 서비스를 오랫동안 방문하기 않아    
   서비스가 보유한 사용자의 과거 데이터가 오래됐을 때 발생하기도 함.   
   Ex] 호텔과 항공편을 예약하는 경우가 있음.    

- 모델이 충분히 빠르게 조정되지 않으면 사용자 관련 추천 사항을    
  다음번 모델 업데이트까지 제공할 수 없음. 그때쯤이면 사용자들은 자신과    
  관련된 아이템을 찾지 못해 이미 서비스를 떠난 뒤일 수도 있음.    

- 모델을 사용자 방문 세션 내에서 각 사용자에 맞게 조정할 수 있다면 모델을 사용자가    
  처음 방문했을 때도 정확하고 관련있는 예측을 수행할 수 있음.    
  성공한 예로는 틱톡 있으며, 틱톡은 동영상 몇 개만 봐도 틱톡 알고리즘을 통해    
  다음에 보고 싶은 은 것을 높은 정확도로 예측.    
  이는 연속학습이 강력함 예측 잠재력을 발휘할수 있음을 보여줌.    

- 연속학습은 배치 학습의 상위개념.

 

- 전통적인 배치 학습이 할 수 있는 모든 것을 할 수 있으며,    
  게다가 연속 학습은 배치 학습만으로 불가능한 유스 케이스에도 적용이 가능.

 

- 연속학습을 세팅하고 수행하는데 드는 노력과 비용이 배치 학습과 동일하다면      
  연속학습을 수행하지 않을 이유가 없음.    
  다만 아직도 연속학습을 세팅하는데 여전히 어려움이 많이 존재.    
  But 연속학습을 위한 MLOps 도구가 성숙하고 있기에,    
  머지 않은 미래에 배치 학습만큼 쉽게 연속 학습을 설정할 수 있게 될 것.     



### 9.1.3 연속 학습의 난제    

- 주요 난제인 신규 데이터 엑세스, 평가, 알고리즘 다룸    


##### 신규 데이터 엑세스 난제     

- 신규 데이터를 확보하는 일   
  매시간 모델을 업데이트하려면 매시간 새로운 데이터 필요    
  현재 많은 기업이 신규 훈련 데이터를 데이터 웨어하우스에서 가져옴    

  데이터를 가져오는 속도는 신규 데이터가 데이터 웨어하우스에 저장되는 속도에 따라 다름   
  데이터 소스가 여러 개면 속도가 느려질 수 잇음   
  대안으로 데이터를 데이터 웨어하우스에 저장하기 전에 가져오도록 허용하는 방법 존재   

  
  애플리케이션에서 데이터 웨어하우스로 데이터를 전송하는 카프카나 키네시스 같은 실시간   
  전송에서 직접 가져옴    
![fig9-3](img/fig9-3.png)


- 신규 데이터 가져오는 것만으로 충분하지 않음   
  모델 업데이트를 위해 신규 데이터 레이블링를 해야함    

- 많은 애플리케이션에서 데이터를 레이블링하는 속도는 모델 업데이트 속도에   
  병목 현상을 일으킴    

- 연속 학습에 가장 적합한 작업은 짧은 피드백 루프로 자연 레이블을 얻을 수 있는 작업    
  Ex] 동적 가격 책정(예상 수요 및 가용성에 기반함), 도착 시간 추정, 주가 예측,    
  광고 클릭률 예측 및 트위, 노래, 짧은 영상, 기사 등 온라인 콘텐츠에 대한 추천 시스템    

- But 자연 래이블은 곧바로 레이블로 생성 x, 사용자들의 행동 데이터를 기반으로    
  시스템의 로그와 함께 조합해 생성되며, 이를 레이블로 추출    

  시스템은 해당 쿠러ㅣ를 해당 추천사항과 매치하고, 해당 추천 사항은 좋은 추천 사항으로   
  레이블링함    


![fig9-4](img/fig9-4.png)


- 레이블을 추출하기 위해 로그를 다시 살펴보는 프로세스를   
  레이블 계산(label computation)라고 함     

- 로그가 늘어날수록 비용이 높음. 레이블 계산은 배치 처리로 수행할 수 있음    
  
  Ex] 배치 작업을 실행해 로그에서 한번에 모든 레이블을 추출하기 전에 먼저 로그가   
  데이터 웨어하우스 저장되기를 기다림   
  But 데이터가 저장될 때까지 기다렸다가 다음 배치작업이 실행될떄까지 또 기다려야 함   
  

  보다 빠른 접근법은 스트림 처리를 활용해 실시간 전송에서 직접 레이블 추출    

- 레이블링 속도가 모델링 개발 반복에 병목 현상을 일으키는 경우,     
  레이블링 프로세슬르 개선 방법 많음   

- 스노클(Snokel) 같은 프로그래밍 방식 레이블링 도구를 활용해   
  사람의 개입을 최소화하면서 빠르게 레이블을 생성하는 방법이 잇음    

- 크라우드소싱된 레이블를 활용해 신규 데이터에 빠르게 레이블링할 수도 있음    


- 스트리밍 도구 아직 초기단계 비용이 높음, But 발전중    



##### 평가 난제     

- 업데이트를 하기 위해 학습 작성하는 것 x(스르립트 작성하면 Easy).     

- 연속 학습의 가장 큰 난제는 해당 업데이트가 모델을 배포하기에 충분한 수준인지   
  확인하는 일    

- 연속 학습은 파괴적 리스크를 증폭시킴
  (파괴적 리스크 ex 운전자 조종장치(autopilot) 신뢰성)    
  
- (1)모델을 자주 업데이트 할수록 업데이트가 실패할 기회가 많아짐    

- (2) 연속 학습은 모델을 조정된 조작(coordinated manipulation)과   
  적대적 공격에 더 취약하게 만듬      

  모델이 실제 데이터를 사용해 온라인 학습하는 경우, 사용자의 악의적인 데이터   
  입력으로 인해 모델이 잘못된 것을 학습하는 문제가 발생할 수 있음  

  ex) 2016 마이크로소프트에서 출시한 chatbot "Tay".   


- 연속 학습을 위한 평가 파이프라인을 설계할 떄, 평가에는 시간이 걸리며    
  이는 모델 업데이트 빈도에 또 다른 병목 현상외 된다는 점 명심    

  Ex] 대형 온라인 결제 회사에서 이상 거래를 감지하는 ML 시스템    
  이상 거래 패턴은 빠르게 변하므로 회사에서는 변화하는 패턴에 적응하도록   
  시스템을 빠르게 업데이트하려고 함     
  But, 해당 작업 데이터 레이블의 불균형 떄문에 어떤 모델이 더 나은지    
  정확히 평가하는 데는 약 2주가 걸림   
  그래서 해당 회사는 2주에 한번만 업데이트 함    

##### 알고리즘 난제     

- 알고리즘 난제는 신규 데이터 난제와 평가 난제에 비해 가벼운 문제    

- 알고리즘은 특정 알고리즘과 특정 훈련 빈도에만 영향을 미침   
  정확히는, 매우 빠르게 업데이트하고자 하는 행렬 기반 모델과    
  트리 기반 모델에만 영향을 줌    

- 2가지 모델 하나는 신경망 하나는 협업 필터링(colloborative filtering 모델과   
  같은 행렬 기반 모델   
  형업 필터링 모델은 사용자-아이템 행렬(user-item matrix)과 같은 차원 축소 기술 사용  

  신경망 모델은 임의 크기의 데이터 배치로 업데이트할 수 있으며 심지어 단 하나의 데이터   
  샘플로도 업데이트 단계를 수행할 수 있음. 반면에 협업 필터링 모델을 업데이트하려면   
  차원 축소를 수행하기에 앞서 전체 데이터셋을 사용해 사용자-아이템 행렬을 구축해야 함   

  물론 신규 데이터 샘플로 행렬을 업데이트할 때마다 행렬의 차원 축소를 적용할 수 있지만.  
  행렬이 크면 차원 축소 단계가 너무 느려 자주 수행하기에는 비용이 높다.    

  따라서 부분 데이터셋으로 학습하는 경우에는 협업 필터링 모델모다 신경망 모델이 적합   

  연속 학습 패러다임에는 행렬 기반 모델이나 트리 기반 모델보다 신경망 같은 모델을    
  적용하는 편이 더 쉬움    
  물론 중복 데이터로 학습하는 트리 기반 모델도 존재     
  호에프딩 트리(Hoeffding Tree)와 그 변형인 호에프딩 윈도 트리(Hoeffding Window Tree) 및   
  호에프딩 적응 트리(Hoeffding Adaptive Tree)    
  다만 이 모델들은 아직 널리 사용 x.  

- 학습 알고리즘뿐 아니라 피처 추출 코드도 부분 데이터셋과 함께 작동해야 함   
  5.2.2절 '스케일링'에서 나오듯 최솟값, 최댓값, 중앙값, 분산과 같은 통계량을 사용해   
  피처를 확장해야 하는 경우 많음   
  이러한 통계량을 계산하려면 전체 데이터셋을 살펴봐야 함   
  
- 다만 모델이 한번에 작은 데이터 부분 집합만 본다면 이론상 데이터의 각 부분 집합에 대한    
  통계량을 계산 가능   
  But, 이는 통계량이 부분 집합에 따라 크게 다름을 의미      
  한 부분 집합으로 계산한 통계량은 다른 부분 집합과 크게 다르므로,    
  한 부분 집합으로 훈련한 모델을 다른 부분집합으로 일반화하기 어려움     


- 서로 다른 부분 집합 간에 통계량을 안정적으로 유지하려면 통계를 온라인으로 계산하는 편이 좋음    

- 모든 데이터의 평균이나 분산을 한번에 사용하는 대신 신규 데이터를 볼 떄마다 통계량을 점진적으로    
  계산하거나 근사합니다.    

- 논문 [Optimal Quantile Approximation in Streams]에서는 이러한 알고리즘을 설명   
  
- 프레임워크들에서는 구간 통계(running statistics)를 계산하는 기능 일부 제공   
  ex] scikit-learn의 StandardScaler에는 구간 통계과 함께 피처 스케일러를 사용한느    
  partial_fit 메서드가 있음   
  다만 프레임워크의 내장 메서드는 속도가 느리며 구간 통계를 폭넓게 지원하지 않음    


### 9.1.4 연속 학습의 네 단계     

- 연속 학습으로 전환하는 과정은 다음처럼 네 단계로 이뤄짐    


#### 1단계: 수동 무상태 재훈련     
- ML 팀은 초기에는 가능한 한 많은 비즈니스 문제를 해결하기 위해  ML 모델 개발에   
  주력함   

  ex] 전자 상거래 웹사이트 회사에서  다음 네 가지 모델을 차례로 개발   
  ```
  1. 이상 거래를 탐지하는 모델    
  2. 사용장에게 관련 상품을 추천하는 모델    
  3. 판매자가 시스템을 악용하는지 예측하는 모델   
  4. 주문 건을 배송하는 데 걸리는 시간을 예측하는 모델
  ```

- 신규 모델 개발에 집중하므로 기존 모델을 업데이트 하는 일은 뒷전    

- 다음 두 가지가 충족될 때만 모델을 업데이트 함.   
  1. 모델 성능이 가져오는 득보다 실이 클 경우   
  2. 팀에서 모델을 업데이트할 시간이 있을 때     

 

- 업데이트 주기는 모델마다 다르며, 어떤 모델은 6개월에 한번    
  어떤 모델은 분기에 한번 어떤건 1년동안 안하기도 함     

 

- 모델 업데이트 프로세스는 수동이며 임시방편적(ad-hoc)임.    

 
- 누군가는 데이터 웨어하우스에 신규 데이터를 쿼리힘.     
  또 다른 사람이 신규 데이터를 정제하고, 데이터에서 피처를 추출하고,    
  이전 데이터와 신규 데이터 모두를 사용해 처음부터 모델을 재훈련한 다음     
  업데이트된 모델을 이진 포팻으로 내보냄.     
  그러면 또 다른 사람이 해당 이진 포맷을 사용해 업데이트된 모델을 배포함.     

- 종종 데이터, 피처, 모델 로직을 캡슐화하는 코드가 재훈련 과정에서 변경되며,    
  변경사항이 프로덕션에 복제되지 않아 추적하기가 어려운 버그가 발생하기도 함.      

- 기술 산업에 속하지 않는 대다수 기업, 예컨대 ML을 도입한 지 3년 미만이고    
  ML 플랫폼 팀이 없는 기업들이 해당 단계에 해당함.     



#### 2단계: 자동 재훈련     

- 몇년 후 ML 팀에서는 모델 몇 개를 배포하는데 성공했고,    
  이 모델들은 명백한 문제를 대부분 해결함.    

- 프로덕션에 적용된 모델을 5개에서 10개 사이. 이때부터는 새로운 모델을 개발하기보다    
  기존 모델을 유지하고 개선하는 일이 우선. 1단계에서 언급한 임시방편적이고    
  수동적인 업데이트 프로세스는 무시하기에는 너무 큰 골칫거리.     
  따라서 팀에서는 모든 재훈련 단계를 자동으로 실행하는 스크립트를 작성하기로 함.    
  작성한 스크립트는 스파크 같은 배치 프로세스를 사용해 주기적으로 실행됨.    

- 어느 정도 성숙한 ML인프라를 갖춘 기업들은 대부분 이 단계에 있음.    
  일부 정교한 기업에서는 최적의 재훈련 빈도를 결정하기 위해 실험을 실행하지만   
  대부분은 재훈련 빈도를 실무자의 직감을 기반으로 설정.     

- 재훈련 프로세스를 자동화하는 스크립트를 생성할 때는    
  시스템 내에 있는 각 모델마다 필요한 재훈련 일정이 다르다는 점을 고려해야 함.   
  또한 모델 간에 종속성이 있으면 자동화 스크립트가 훨씬 복잡해짐.    


***요구사항***

프로덕션에 적용된 ML 모델이 있는 회사라면    
자동 재훈련에 필요한 인프라를 대부분 보유하고 있음.    
이 단계의 실행 가능성은 스크립트 작성의 실행 가능성을 중심으로 하며,    
이때 스크립트는 워크 플로를 자동화하고,     
다음 작업을 자동으로 수행하도록 인프라를 구성.

 
1. 데이터를 가져옵니다.   
2. 필요시 데이터를 다운샘플링하거나 업샘플링합니다.    
3. 피처를 추출합니다.    
4. 레이블링 작업과 그에 대한 처리를 수행해 훈련 데이터를 생성합니다.    
5. 훈련 과정을 시작합니다.    
6. 새로 훈련한 모델을 평가합니다.    
7. 모델을 배포합니다.     


- 스크립트를 작성하는데 걸리는 시간은    
  스크립트 작성자의 역량을 비롯한 여러 요인에 따름.     

- 스크립트의 실행 가능성에 영향을 미치는 주요 요소 세 가지.     

 
1. 스케줄러
  작업 스케일링을 처리하는 도구.  스케줄러가 없다면 이를 설정하는데 시간이 필요합.   
  But 에어플로(Airflow)나 아고(Argo) 같은 스케줄러가 이미 있다면 스크립트를 연결하기가 그리 어렵지 않음.     

2. 데이터의 가용성과 접근성    
  데이터를 데이터 웨어하우스에 직접 수집해야 하나요?   
  여러 조직의 데이터를 결합해야 하나요?   
  처음부터 많은 피처를 추출해야 하나요?   
  데이터 레이블링도 해야 하나요?    
  ' 예' 라고 답하는 질문이 많을수록 스크립트를 설정하는 데 드는 시간이 많음.    

3. 모델스토어     
  모델 스토어로 모델을 재현하는데 필요한 모든 아티팩트를 자동으로 버전화하고 저장.   
  가장 간단한 모델 스토어는 구조화된 방식으로 직렬화된 모델 개체를 저장하는 S3 버킷.    
  다만 S3 같은 개체 스토리지는 아티팩트 버전 관리에 좋지 않으며 사람이 읽을수 없음.   
  따라서 관리형 서비스인 아마존 세이지메이커나 오픈 소스인 데이터브릭스 ML플로같이 보다 성숙한 모델 스토어가 필요.    
 
***피처 재사용(Log and wait)***   

추출된 피처를 모델 재훈련에 재사요해 계산 비용을 절약하고 예측과 훈련 간의 일관성을 갖게 함    
이 접근법이 바로 "Log and wait".    
이는 훈련-서빙 편향을 줄이는 고전적 접근법(8.1.2 머신러닝 한정 장애)의 '프로덕션 환경 데이터가    
훈련 데이터와 다른 경우 참조)    

"Log and wait" 점점 대중화되고 있음    
페어(Faire)의 데이터 과학자 샘 케니(Sam Kenny) 작성한 블로그글 참고   



#### 3단계: 자동 상태 유지 훈련      

- 2단계에서는 모델을 재훈련 할 때 매번 처음부터 모델을 훈련(무상태 재훈련).     
  따라서 재훈련 비용이 높으며 재훈련 빈도가 높다면 특히 비용이 많이 듬.    


- 이 단계에서는 자동 업데이트 스크립트는 재구성함. 모델 업데이트가 시작되면 현재 체크포인트에 대한 훈련을    
  계속하기에 앞서 이전 체크포인트를 찾아 메모리에 올림.   



 

##### <요구사항>

- 이 단계에서 가장 필요한 것은 사고방식 변화.    

- 보통 모델을 처음부터 훈련하는 것이 일반적이라고 생각하는데, 이는 많은 기업에서 데이터 과학자가 매번 처음부터 모델을 훈련하고    
  엔지니어에게 전달해 배포하는 데 너무 익숙해졌기 때문. 그렇기에 상태 유지 훈련이 가능하도록 인프라를 설정하는 것은 고려하지 않음.    

- 일단 상태 유지 훈련에 전념하면 업데이트 스크립트를 재구성하는 일은 간단함.    

- 이 단계에서 가장 필요한 것은 데이터 및 모델 계보를 추적할 방법.     

  먼저 모델 버전 1.0을 업로드 한다고 상상했을 때, 이 모델을 신규 데이터로 업데이트해 모델 버전 1.1을 생성하고,    
  마찬가지로  업데이트해 모델 1.2를 생성. 이제 또 다른 모델을 업로드하고 모델 버전 2.0이라고 부름.        
  이 모데을 신규 데이어로 업데이트해 모델 버전 2.1을 생성. 이런 식으로 다양한 모델 버전이 생성됨.     
 

- 모델을 재현하고 디버깅하기 위해서는 모델이 시간에 따라 어떻게 발전하는지,    
  어떤 모델이 기본 모델로 사용됐는지, 업데이트에 어떤 데이터를 사용했는지 등의 정보가 필요함.       
  이때, 기존 모델 스토어에는 모델 계보 기능이 없으므로 사내에서 솔루션을 구축해야 합니다.   

 
- 데이터 웨어하우스 대신 실시간 전송에서 데이터를 가져오려는데 스트리밍 인프라가    
  충분히 성숙하지 않았다면 스트리밍 파이프라인을 변경하는 과정이 필요함.    


#### 4단계: 연속 학습     
- 3단계에서는 모델이 개발자가 설정한 일정에 따라 계속 업데이트됨.    
  최적의 일정은 찾기가 간단하지 않으며 상황에 따라 달라짐.   

- 따라서 업데이트 일정을 고정하는 대신 데이터 분포가 변하고 모델 성능이 떨어질 때마다    
  모델이 자동으로 업데이트 되도록 함.    

 

- 최종 목표는 연속학습과 에지 배포를 결합할 때.

 
- 기존 모델을 신규 디바이스에 배포한다고 가정 시.
  디바이스에 있는 모델은 중앙 집중식 서버와 동기화 할 필요 없이 환경에 따라 지속적으로 업데이트하고 적응.  
  물론 중앙 집중식 서버 비용도 발생하지 않음.게다가 디바이스와 클라우드 간에 데이터를 주고 받을 필요가 없으므로    
  데이터 보안 및 개인 정보 보호 기능이 향상됨.    

 

##### <요구사항>     

- 3단계에서 4단계로 넘어가는 과정은 험난함.    
  먼저 모델 업데이트를 트리거하는 메커니즘이 필요함.    
 

- 트리거

```
시간 기반 : 예컨대 5분마다 업데이트합니다.
성능기반 : 예컨데 모델 성능이 떨어질때마다 업데이트합니다.
볼륨 기반 : 예컨에 레이블링된 데이터 총량이 5% 증가할 때마다 업데이트 합니다.
드리프트 기반 : 예컨대 주요 데이터 분포 시프트가 감지될 때마다 업데이트 합니다.
 
```

- 이 트리거 메커니즘이 작동하려면 견고한 모니터링 솔루션이 필요함.   
  모델 업데이트 함수를 작성하는 것은 3단계와 크게 다르지 않음.    
  다만 업데이트된 모델이 제대로 작동하는지 확인하는 것은 어려운 부분.    
  따라 프로덕션에서 테스트르 통해 이를 확인함.    

 



```
test code
```
