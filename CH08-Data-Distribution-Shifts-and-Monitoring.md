# CH08 데이터 분포 시트프와 모니터링(Data Distribution Shifts and Monitoring)     

- 모델 성능은 프로덕션 환경에서 시간에 따라 저하됨   

- 모델 배포 후에도 이슈를 탐지하기 위해 성능을 지속적으로 모니터링해야 하며   
  발생한 이슈를 수정하는 업데이트를 계속 배포해야함.   
- ML 모델이 프로덕션 환경에서 실패하는 이유 중 '데이터 분포 시프트(shift)' 가 있는데,    
  이는 프로덕션 환경의 데이터 분포가 훈련하는 동안 모델에 노출된 데이터 분포와 다르거나 괴리가 점차 커질 때 발생함.    

- 프로덕션 환경에서 동작하는 ML 모델 대부분에 영향을 미칠 만큼 만연함   




## 8.1 머신러닝 시스템 장애 원인     

- 장애는 시스템에 대한 기대치가 한가지 이상 어긋날 때 일어남   

- 전통적인 소프트웨어에서는 주로 시스템 운영에 대한 기대치,   
  즉 시스템 로직이 레이턴시와 스루풋 같은 운영 지표의 기대 범위 안에서 실행되는지가 중요함     

- ML 시스템에서는 운영 지표와 ML 성능 지표 모두 신경 써야 함     
  Ex] 영어-프랑스 기계 번역의 운영 기대치는 영어 문장을 입력하면 시스템이 바로 레이턴시 1초 안에 프랑스어 번역문을 출력해 내는 것이고,     
  ML 성능상 기대치는 출력 중 99%는 주어진 영어 문장을 정확히 번역한 문장이어야 한다는 것임.    
  출력한 번역이 정확하지 않다고 해서 반드시 시스템 장애는 아님, 정확도 기대치는 약간의 오차를 허용함.  
  하지만, 서로 다른 영어 문장을 시스템에 연달아 입력하는데 계속해서 잘못된 번역문이 나온다면 두 번째 기대치를 어기므로 시스템 장애임.   

- 운영상 기대치를 어기는 문제는 감지하기가 쉬움.   
  시간 초과, 웹 페이지 404 오류, 메모리 부족, 세그멘테이션 결함 등 운영 중단을 수반하기 때문임.  
  그러나 ML 성능상 기대치를 어기는 문제는 프로덕션 환경에서 ML 모델 성능을 측정하고 모니터링해야 하므로 감지하기가 보다 어려움.     
  영어 - 프랑스어 기계 번역 시스템 예시에서 올바른 번역문이 무엇인지 모른다면 출력된 번역문 중 99%가 옳은지 그른지 판단하기 어려움.    
  사용자가 구글 번역문이 오역임을 인지하지 못해 오역을 사용하는 사례는 셀 수 없이 많은데      
  이러한 이유로 ML 시스템은 조용히 실패(fail silently) 한다고 함.     



### <8.1.1 소프트웨어 시스템 장애>     

- 소프트웨어 시스템 장애는 ML에 속하지 않는 시스템에서 발생하는 장애임    

  [1] 의존성 장애 :    
  시스템이 의존성을 갖는 소프트웨어 패키지 혹은 코드베이스에 중단이 발생해 시스템이 중단되는 경우임    
  서드 파티가 의존성을 유지 관리 할 때 흔히 발생하며, 의존성을 유지 관리하는 서드 파티가 더 이상 존재하지 않는 경우 특히 자주 발생   

  [2] 배포 실패 :    
  배포 오류로 인한 실패.    
  모델이 현재 버전 대신 실수로 이전 버전 바이너리를 배포하거나 시스템에 특정 파일을 읽거나 쓰기 권한 없는 경우   

  [3] 하드웨어 오류 :    
  CPU나 GPU처럼 모델 배포에 사용하는 하드웨어가 제대로 작동하지 않는 경우      
  예를 들면 사용하던 CPU가 과열돼 고장남       

  [4] 다운타임 또는 충돌:     
  시스템 구성 요소가 다른 곳에 있는 서버, AWS나 호스팅 서비스에서 실행되는 경우 해당 서버가 다운되면 시스템도 따라서 다운됨     

- 소프트웨어 시스템 장애를 해결하려면 ML 기술이 아니라 전통적인 소프트웨어 엔지니어링 기술이 필요함.     
  ML 시스템 배포에도 전통적인 소프트웨어 엔지니어링 기술이 중요한 만큼 ML 엔지니어링은 보통 ML이 아닌 엔지니어링에 중점을 둠       

- 소프트웨어 시스템 장애가 만연한 이유는 업계에서 ML 도입이 아직 초기 단계이고, 따라서 ML 프로덕션 환경을 위한 도구가 한정적이고     
  아직 모범 사례가 잘 개발되거나 표준화되지 않았기 때문임   




### <8.1.2 머신러닝 한정 장애>     


- ML 한정 장애는 ML 시스템과 관련된 장애임   
  Ex] 데이터 수집과 처리에 문제가 있을 때, 하이퍼파라미터에 문제가 있을 때, 추론 파이프라인의 변경 사항이 학습 파이프라인에    
  제대로 복사되지 않았을 때(혹은 그 반대), 데이터 분포 시프트로 모델 성능이 시간에 따라 저하 될 때, 에지 케이스, 퇴행성 피드백 루프 등이 있음    
- ML 한정 장애는 전체 장애에서 차지하는 비중은 낮지만 탐지하거나 수정이 어렵고,     
  ML 시스템이 온전히 사용되지 못하게 하므로 ML이 아닌 영역의 장애보다 훨씬 더 위험함    
  일단 여기서는 모델 배포 후에 발생하는 (1) 프로덕션 데이터가 훈련 데이터와 다른 경우,    
  (2) 에지 케이스(edge case), (3) 퇴행성 피드백 루프(degenerate feedback loop) 등을 나열한다.       

(1) 프로덕션 환경 데이터가 훈련 데이터와 다른 경우     
- ML 모델을 훈련 데이터로 학습함은 모델이 훈련 데이터에 내재된 분포를 학습한 후에    
  그 학습된 분포를 통해 훈련 중 본 적 없는 데이터에 대해 정확한 예측값을 만들어냄을 의미함       
- '데이터 분포 시프트' 는 수학적으로 의미하는 바가, 모델이 본 적 없는 데이터에 대해    
  정확한 예측값을 만들어낸다면 이 모델이 '본 적 없는 데이터에도 충분히 일반화' 됐다고 얘기함    
- 개발 중 모델 평가에 사용하는 테스트 데이터는 본 적 없는 데이터여야 하며 이에 대한 모델 성능은 모델이 얼마나 잘 일반화될지 가늠하게 해줌       


- ML 교과 과정에서 먼저 배우는 것 중 하나는 훈련 데이터와 본 적 없는 데이터가 유사한 분포에서 나와야 한다는 것임    
  즉, 본 적 없는 데이터를 훈련 데이터 분포와 동일한 '정상 분포(stationary distribution)' 에서 추출했다고 가정함.    
  본 적 없는 데이터를 다른 분포에서 추출하면 모델이 제대로 일반화되지 않을 수 있음.     

  => 이 가정은 대개 올바르지 않을 수 있음.    
  첫 째로, 실제 데이터에 내재된 분포는 훈련 데이터에 내재된 분포와 같지 않을 수 있음.     
  훈련 데이터셋이 모델이 프로덕션 환경에서 접할 데이터를 정확하게 표현하도록 큐레이팅 하기는 어려움.    
  실제 데이터는 다면적이고 많은 경우에 변형이 무한에 가까운 반면, 훈련 데이터는 유한하고     
  데이터셋 생성과 처리에 사용할 수 있는 시간/연산/인적 자원에 의해 제한됨    
  다양한 종류의 선택이나 샘플링 편향이 존재함    


- 현실 데이터가 훈련 데이터와 매우 달라져서, 이러한 데이터 분포의 차이는 다른 유형의 이모티콘 인코딩을 사용하는 현실 데이터처럼    
  매우 사소한 것에 기인할 수 있음 => 이러한 유형의 차이를 훈련-서빙 편향(trin-serving skew) 이라는 흔한 장애 모드를 야기함     
  : 모델이 개발 시에는 훌륭하지만 배포 후 성능은 그다지 좋지 않은 현상     


- 둘째로, 현실 세계는 정상성(stationarity)를 갖지 않음     
  모든 것은 변하며, 데이터 분포는 시프트함   
  모델이 처음 배포될 때는 훌륭하게 작동하지만 시간에 따라 데이터 분포가 변하면서 성능이 저하됨     

- 데이터 시프트를 유발하는 예시로 코로나19 사례를 들면 사람들은 데이터 시프트     
  비정상적인 이벤트 때문에 발생한다고 생각하기 쉬워, 자주 발생하지 않는다고 생각함     
  그러나, 데이터 시프트는 항상, 갑자기, 점진적으로 혹은 계절성을 띠며 발생함     

  특정 이벤트 때문에 갑자기 발생하는 예시는 기존 경쟁자가 가격 정책을 변경해서     
  이에 대응하기 위해 가격 예측을 업데이트해야 하는 경우, 새로운 지역에서 제품을 출시하거나     
  유명인이 제품을 언급해 신규 사용자가 급증하는 경우 등이고      

  점진적으로 발생하는 예는 사회 규범, 문화, 언어, 트렌드,     
  산업과 같이 시간에 따라 변화하는 경우와 계절적 변화 때문에 발생하는 예시이다.     


- 모니터링 대시보드에서 데이터 시프트처럼 보이는 것들은 사실 대부분 내부 오류임     
- ML 시스템의 복잡성과 잘못된 배포 관행 때문인데, 데이터 파이프라인의 버그/잘못 입력된 결측값/훈련과 추론 시    
  추출한 피처 간의 불일치/잘못된 데이터 하위 집합의 통계를 적용해 표준화한 피처/잘못된 모델 버전    
  또는 사용자 행동을 바꾸게 강제한 앱 인터페이스상 버그 등이 원인이 될 수 있음    


#### (2) 에지 케이스    
- ML 모델이 대부분 잘 작동하더라도 낮은 확률로 장애가 발생해 치명적인 결과를 유발한다면 모델 사용 자체가 어려워짐     
  주요 자율 주행 자동차 회사들은 시스템이 에지 케이스에서 잘 작동하도록 하는 데 최선을 다하고 있음      

- 에지 케이스란 너무 극단적이여서 모델이 치명적인 실수를 하게 되는 데이터 샘플을 말함      
  에지 케이스는 보통 동일한 분포에서 나온 데이터 샘플이지만, 모델이 잘 작동하지 않는 데이터 샘플 수가 급증했다면    
  내재된 데이터의 분포가 시프트하지 않았나 의심해봐야 함     
- 에지 케이스가 배포된 ML 시스템을 망가뜨리는 사례로 자율 주행 자동차를 이야기 하는데,    
  안전이 중요한 모든 애플리케이션이 이러한 사례에 해당한다.     
  또한, 안전이 중요하지 않은 애플리케이션도 고객 서비스 챗봇이 문의에 대개 합리적으로 응답하지만 인종 차별적이거나    
  성차별 적인 내용을 뱉는다고 생각하면 브랜드 이미지에 좋지 않아 사용하기 어려워짐      


***에지 케이스와 이상치***

- 에지 케이스와 이상치에 대한 차이점을 살펴보면, 에지 케이스의 구성 요소에 대한 정의는 분야에 따라 다르다.      
  ML은 최근에 프로덕션 환경에 도입되기 시작해서, 에지 케이스가 계속 발견되고 있다.      
  따라서 용어 정의에 논란의 여지가 생기고 있다      
- 여기서의 이상치란 다른 데이터 포인트와 성질이 크게 다른 데이터 포인트 데이터를 의미하는데,     
  에지 케이스는 성능을 의미한다.     
- 다른 데이터 포인트보다 모델 성능이 크게 뒤떨어지는 데이터 포인트임     
- 이상치 또한 모델 성능이 비정상적으로 저조한 원이 될 수 있어 에지 케이스에 포함되기도 함      
- 다만 모든 이상치가 에지 케이스는 아님      
  Ex] 고속 도로를 무단 횡단 하는 사람이 이상치이지만,     
  자율 주행 자동차가 그 사람을 정확하게 탐지하고 그에 대한 반응을 적절하게 판단할 수 있다면 에지 케이스가 아님.   
- 모델 개발 중에 이상치가 모델 성능에 부정적인 영향을 미치기도 하는데,    
  많은 경우 모델이 더 나은 결정 경계를 학습하고 본 적 없는 데이터에 더 잘 일반화되도록 이상치를 제고하곤 함.    
  그러나, 일반적으로 추론 과정에서 다른 질의문과 성격이 크게 다른 질의문을 제거하거나 무시할 수 없음.  


#### (3) 퇴행성 피드백 루프.     

- 피드백 루프는 예측값을 제시한 다음 예측값에 대한 피드백이 되돌아올 때까지 걸리는 시간을 의미함.       

- 피드백은 자연 레이블을 추출해 모델 성능을 평가하고 다음번 훈련을 반복하는데 사용 가능함.      

- 퇴행성 피드백 루프(degenerate feedback loop)는 예측 자체가 피드백에 영향을 미치고,   
  이 피드백이 모델의 다음번 반복 학습에 영향을 미칠 때 발생함     

- 퇴행성 피드백 루프는 시스템 출력을 시스템의 미래 입력을 생성하는 데 사용할 때 발생하고,    
  이것은 시스템 미래 출력에 다시 영향을 미침     

- ML에서 시스템의 예측은 사용자가 시스템과 상호 작용하는 방식에 영향을 미침     

- 시스템과 사용자의 상호 작용은 때때로 같은 시스템에 대한 훈련 데이터로 사용되므로    
  퇴행성 피드백 루프가 발생하면서 의도하지 않은 결과를 초래할 수 있음

- 퇴행성 피드백 루프는 추천 시스템과 광고 클릭률 예측 등    
  사용자에게서 획득한 자연 레이블이 존재하지 않는 작업에서 특히 흔함

  Ex] 사용자가 좋아할 말한 노래를 추천하는 시스템을 개발한다고 가정할 때, 시스템에서 순위가 높은 노래가 사용자에게 먼저 보이게 됨.    
  가장 먼저 보이면 사용자가 더 많이 클릭하게 되고 시스템은 이 추천 항목이 적절하다고 확신하게 됨.     
  처음에는 두 곡 A와 B의 순위가 미세하게 달랐고, A가 좀 더 높은 순위에 있어서 추천 목록에 좀 더 상단에 보여지게 되었으나,    
  사용자가 잘 보이는 곳에 있는 A를 더 많이 클릭하게 되고 시스템에서 A의 순위가 B보다 올라가게 된다.   

  퇴행성 피드백 루프는 인기 있는 영화, 도서, 음악이 점점 더 인기를 얻는 이유를 설명하는 한 가지 요소이며    
  프로덕션 환경에서는 이러한 현상이 나타나는 시나리오가 매우 보편적이고 많이 연구되어 왔음.    

  => 이를 '노출 편향', '인기도 편향', '필터 거품', '에코 체임버' 등으로 불리게 됨.   

- 퇴행성 피드백 루프의 위험성은, 이력서 기반 지원자가 특정 직무에 적합한지 예측하기 위한    
  심사 모델을 개발했을 때와 같이 특정 피처 X에 높은 가중치를 부여하게 되면서 발생할 수 있음.     
  이는 모델에 대한 각 피처의 중요도를 측정하는 식으로 모델이 예측을 수행하는 방식에 대한   
  가시성을 확보하여 특정 피처에 대한 편향을 감지한다.    

- 사람이 관여하지 않으면 퇴행성 피드백 루프로 인해 모델이 최적 성능에 못 미치는 상태로 계속 동작함.    
  최악의 경우 데이터에 존재하는 편향이 영속화되고 확대됨.    


##### 퇴행성 피드백 루프 감지     
- 시스템이 오프라인일 때는 퇴행성 피드백 루프를 감지하기 어려움     

- 퇴행성 루프는 사용자 피드백으로 인해 발생하는데 시스템이 온라인 상태가 되기 전까지(사용자에게 배포되기 전까지)는 사용자가 존재하지 않기 때문임     

- 추천 시스템에서는 시슽메이 오프라인일 때도 시스템 출력 인기도의 다양성을 측정해 퇴행성 피드백 루프르 감지할 수 있음     
  항목의 인기도는 과거에 상호 작용(열람/좋아요/구매 등)이 일어난 횟수를 기반으로 측정함      
  모든 항목의 인기도는 롱테일 분포를 따라서, 소수 항목만 다수 사용자와 상호 작용이 발생하고   
  대부분 항목은 상호 작용이 거의 발생하지 않음     
  '롱테일 항목(long-tail item')의 총체적 다양성(aggregate diversity)와    
  평균 적용 범위(average coverage)의 여러 지표들은 추천 시스템 출력의 다양성을 측정하는데 도움이 될 수 있음     
  => 낮은 점수는 시스템 출력이 단조로움을 의미하고, 이는 인기도 편향으로 발생할 수 있음    



***퇴행성 피드백 루프 교정***      
- 퇴행성 피드백 루프는 흔한 문제여서 이를 교정하는 방법은 (1) 무작위화 사용 (2) 위치 피처 사용이 있다     

  (1) 무작위화     

- 퇴행성 피드백 루프로 인해 시간에 따라 시스템 출력이 점차 단조로워질 수 있는데,    
  예측에 무작위화를 도입하면 단조로움을 줄일 수 있음       
  추천시스템에서 순위가 높은 항목만 보여주는 대신 무작위 항목을 보여주고    
  사용자 피드백을 받아서 항목의 실제 경쟁력을 결정함    
  : 틱톡에서 사용 중    

- 무작위화는 다양성을 개선하지만 사용자 경험을 저하할 수 도 있음    

- 적당한 규모의 무작위화와 인과 추론 기술을 사용해 편향되지 않은,    
  본래의 가치를 추정하는 방법이 있음

- 퇴행성 피드백 루프는 예측에 대한 사용자 피드백으로 인해 발생하고,    
  예측에 대한 피드백은 보이는 위치에 따라 편향된다.

  (2) 위치 피처(positional feature)   

- 예측값이 보여지는 위치가 피드백에 어떤 식으로든 영향을 미치는 경우 위치 피처를 사용해 위치 정보를 인코딩 한다.   
  '위치 임베딩' 과는 다름

  Ex], 퇴행성 피드백 루프를 완화하기 위해 훈련 데이터에 위치 피처를 추가할 수 있는데,    
  노래 추천과 같은 경우 '최상단 추천 여부'를 피처로 추천하여 피처를 통해 모델이 최상단 추천 여부가    
  클릭 여부에 얼마나 영향을 미치는지 알 수 있다.     
  추론할 때는 노래가 추천되는 위치에 상관없이 사용자가 노래를 클릭할지 예측하는 것이 목표이므로,    
  최상단 위치 피처 값을 '아니오'로 설정하고, 사용자가 여러 곡들에 대해 모델 예측값을 보고     
  각 노래를 보여줄 순서를 결정한다.     
- 보다 정교한 방법은 두 가지 모델으 사용하는 것으로, 첫 번째 모델은 추천이 보이는 위치를 고려해 사용자가   
  추천을 살펴보고 고려할 확률을 예측하는 것과 두 번째 모델은 사용자가 살펴보고 선택을 고려한 항목을   
  최종적으로 클릭할 확률을 예측하는 것이다. 두 번째 모델은 위치와는 전혀 관련이 없다.     


## 8.2 데이터 분포 시프트       

- 데이터 분포 시프트는 지도 학습에서 모델이 동작하는 데이터가 시간에 따라 변하는 현상으로,    
  모델 예측도 시간이 지날수록 덜 정확해짐     

- 모델이 훈련된 데이터의 분포를 ***원본 분포(source distribution)*** 이라고 하며,      
  모델이 추론을 실행하는 데이터의 분포를 ***대상 분포(target distribution)*** 이라고 함        

### 8.2.1 데이터 분포 시프트 유형       

- 데이터 분포 시프트는 종종 (1) covarinace shift, (2) label shift, (3) concept drift와     
  동일한 의미로 사용도지만, 이 세 가지 개념은 데이터 시프트의 하위 유형임     

- 다양한 시프트 유형에 대한 논의는 수학적임. 데이터 시프트를 감지하고 효율적인 알고리즘을      
  개발하기 위해서는 시프트 원인을 이해해야 함      

- 모델에 대한 입력을 X, 출력을 Y 라고 할 때,     
  지도 학습에서 훈련 데이터는 결합 분포 P(X,Y)의 샘플 집합으로 볼 수 있으며     
  ML은 일반적으로 P(Y|X)를 모델링함.     
  이 결합분포 P(X,Y)는 두 가지 방식으로 분해 될 수 있음     
  (1) P(X,Y) = P(Y|X)P(X)    
  (2) P(X,Y) = P(X|Y)P(Y)     

  P(Y|X)는 입력이 주어졌을 때 출력의 조건부 확률을 나타냄    
  Ex] 이메일 내용이 주어졌을 때 이메일이 스팸일 확률로,    
  P(X)는 입력의 확률 밀도 함수를 나타내며 P(Y)는 출력의 확률 밀도 함수를 나타냄   


(1) Covariate shift   
P(X)가 변하지만 P(Y|X) 는 동일하게 유지됨  

(2) Label shift  
P(Y)가 변하지만 P(X|Y)는 동일하게 유지됨 

(3) Concept drift  
P(Y|X)가 변하지만 P(X)는 동일하게 유지됨  



#### 공변량 시프트(Covariance shift)     

- 통계학에서 공변량은 주어진 통계적 시행 결과에 영향을 미칠 수 있지만    
  직접적인 관심 대상은 아닌 독립 변수임.    
  Ex] 지리적인 위치가 주택 가격에 미치는 영향을 확인하기 위해 실험한다고 가정할 때,     
  직접적인 관심사는 주택 가격이라는 변수이고 넓이라는 변수는 가격에 영향을 미치므로 공변량인 셈임.     

- 지도 학습에서는 레이블이 직접적인 관심 변수고 입력 피처는 공변량 변수임.    

- 공변량 시프트는 P(X)가 변하지만 P(Y|X)는 동일하게 유지되는 경우로,     
  입력의 분포는 변하지만 입력이 주어졌을 때 출력의 조건부 확률은 동일하게 유지되는 것임.   

  Ex] 유방암을 감지하는 작업에서 여성이 40세 이상이면 유방암에 걸릴 확률이 더 높으므로     
  입력 변수는 '나이' 임. 추론 데이터보다 훈련 데이터에서 40세 이상 여성이 더 많다면     
  훈련 및 추론 데이터의 입력 분포가 상이함.    
  But, 연령이 정해진 데이터 포인트 예를 들어 40세 이상인 데이터 포인트가 유방암에 걸릴 확률은 일정함.     
  즉 P(Y|X), 즉 40세 이상이 유방암에 걸릴 확률은 같음.   

- 모델 개발 시 데이터 선택 프로세스에서 내재된 편향 때문에 공변량 시프트가 발생할 수 있음  

- 이 편향이 생기는 이유는 특정 클래스의 샘플을 수집하기가 어렵기 때문임   

  Ex] 유방암을 연구하기 위해 여성들이 주로 유방암 검사를 받으러 가는 병원에서 데이터를 얻었다고 가정할 때,     
  40세 이상이면 검진을 권유받으므로 병원 데이터의 대부분은 40세 이상 여성임     
  => 이러한 이유로 공변량 시프트는 샘플 선택 편향 문제와 밀접하게 관련됨.     

- 공변량 시프트는 모델이 좀 더 쉽게 학습할 수 있도록 훈련 데이터를 인위적으로 변경할 때 발생함.   

- ML 모델 학습은 불균형 데이터셋에서 더 어려움.    
  드물게 발생하는 클래스에 대해 더 많은 샘플을 수집하거나,     
  모델이 드문 클래스를 더 잘 학습하도록 해당 클래스에 대한 데이터를 오버샘플링함.      

- 공변량 시프트는 모델 학습 프로세스, 특히 능동적 학습 프로세스 때문에 생기기도 함.     

능동적 학습 : 모델을 훈련할 샘플을 무작위로 선택하는 대신 휴리스틱에 따라 해당 모델에 가장 유용한 샘플을 선택하는 방법. 

- 훈련 입력 분포가 실제 입력 분포와 다르게 학습 프로세스에 의해 변경되면서 공변량 시프트가 의도치 않게 동반됨  

- 프로뎍션 환경에서 공변량 시프트는 일반적을 환경,    
  애플리케이션 사용 방식이 크게 변함에 따라 발생함.    

  Ex] 모델이 무료 사용자가 유료 사용자로 전환할 가능성을 예측한다고 가정할 때     
  사용자의 소득 수준을 피처로 잡는다. 그러나, 최근 회사의 마케팅 부서는 현재보다 더 소득이 높은 사용자를     
  끌어들이는 캠페인을 시작했으므로, 모델의 입력 분포가 변하지만 ㅅ호득이 동일할 때 사용자의 전환 확률은 여전히 동일함.   

  - 실제 입력 분포가 훈련 입력 분포와 어떻게 다를지 미리 알 수 있다면    
    중요도 가중치 조정(importance weighting)과 같은 기술로 현실 데이터에   
    잘 작동하도록 모델을 훈련할 수 있음   

  => 중요도 가중치 조정은   
  실제 입력 분포와 학습 입력 분포 간의 밀도 함수 비율을 추정하고,   
  이 비율에 따라 학습 데이터에 가중치를 부여하고 이 가중치 데이터로 ML 모델을 학습함    

- 그러나 현실에서는 분포가 어떻게 변하는지 미리 알 수 없어서,   
  모델을 새로운 미지의 분포에 강건하도록 선제적으로 학습시키는 일은 어려움.     



#### 레이블 시프트(Label shift)      

- 레이블 시프트는 P(Y)가 변하지만 P(X|Y)가 동일하게 유지되는 경우를 말하며   
  사전 시프트, 사전 확률 시프트, 목표 시프트라고 함      

- 출력 분포가 변하지만 주어진 출력에 대한 입력 분포는 동일하게 유지되는 경우로 생각함     

- 위에서 공변량 시프트는 입력 분포가 변하는 경우로, 입력 분포가 변하면 출력 분포도 변해    
  공변량 시프트와 레이블 시프트가 동시에 발생함     
  공변량 시프트에 대한 유방암 예씨에서 40세 이상 여성이 추론 데이터보다    
  훈련 데이터에 더 많아 양성 레이블 비율이 훈련 과정에서 더 높은데,     
  훈련 데이터에서 유방암에 걸린 사람 A를 무작위로 선택하고,     
  테스트 데이터에서 유방암에 걸린 사람 B를        
  무작위로 선택한다면 A와 B가 40세 이상일 확률은 동일함          

  => 즉, P(Y), 즉 유방암에 걸린 사람이 40세 이상일 확률은 동일하여,    
  레이블 시프트에 해당함       

  그러나 공변량 시프트가 반드시 레이블 시프트를 동반하는 것은 아님    
  Ex] 여성이 유방암에 걸릴 확률을 줄여주는 예방약이 있는데,    
  확률 P(X)는 모든 연령대의 여성에 대해 감소하므로 공변량 시프트에 해당하지 않음     
  하지만, 유방암에 걸린 사람의 경우 연령 분포가 동일하게 유지되므로     
  이것은 여전히 레이블 시프트임      

  레이블 시프트는 공변량 시프트와 밀접하게 관련되므로 모델이 감지하고     
  레이블 시프트에 맞게 조정하는 방법은 공변량 시프트 시의 조정 방식과 비슷함.     


#### 개념 드리프트(Concept drift)    

- 사후 시프트(posterior shift)라고 하는 concept drift는 입력 분포가 동일하게     
  유지되지만 정해진 입력에 대한 출력의 조건부 분포가 변하는 경우임.     

- 동일한 입력, 상이한 출력으로 주책 관련 피처를 기반으로 주택 관련 피처를    
  기반으로 주택 가격을 예측하는 모델을 가정하면,    
  샌프란시스코에 있는 아파트가 코로나 19 이전 200달러였지만,     
  초기에는 많은 사람들이 샌프란시스코를 떠나 150만 달러가 됨.    

- 많은 경우 개념 드리프트는 주기적거나 계쩔적임.    
  승차 공유 가격은 주중과 주말 사이 변하고, 항공권 가격은 휴가철에 올라감.    

- 기업들은 주기적, 계절적 드리프트를 처리하기 위해 여러 모델을 사용함    


#### 일반적인 데이터 분포 시프트     
- 현실에서 모델 성능을 저하할 수 있는 몇가지 변화 유형이 있는데,     
  바로 피처 변화(feature change) 이다.     

- 신규 피처가 추가되거나, 이전 피처가 제거되거나,    
  피처 값의 가능한 범위가 변한 경우이다.
  모델이 '연령' 피처에 연 단위를 사용하다가 이제는 '월' 단위로 사용한다면     
  해당 피처 값의 범위가 변하게 됨   
- 레이블 스키마 변화(label schema change)는    
  Y 값의 가능한 범위가 변하는 경우이다. 레이블 시프트의 경우 P(Y)는 변하지만    
  P(X|Y)는 그대로 유지된다.   
  반면 레이블 스키마가 변하면 P(Y)와 P(X|Y)가 모두 변하게 된다.     
  스키마는 데이터 구조를 설명하므로 특정 작업에 대한 레이블 스키마는     
  해당 작업의 레이블 구조를 설명하므로, 클래스를 정숫값에   
  대응시키는 딕셔너리는 스키마이다.     

- 레이블 스키마 변화는 제품이나 문서에 대한 범주화     
  같은 고차원 카디널리티 작업(클래스가 많은 작업)에서 흔하게 발생함     

- 한 번에 한 가지 유형의 시프트만 발생하는 법은 없고,    
  모델의 여러 유형의 drift가 한꺼번에 발생할 수 도 있다.      








