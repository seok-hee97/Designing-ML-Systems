# CH08 데이터 분포 시트프와 모니터링(Data Distribution Shifts and Monitoring)     

- 모델 성능은 프로덕션 환경에서 시간에 따라 저하됨   

- 모델 배포 후에도 이슈를 탐지하기 위해 성능을 지속적으로 모니터링해야 하며   
  발생한 이슈를 수정하는 업데이트를 계속 배포해야함.   
- ML 모델이 프로덕션 환경에서 실패하는 이유 중 '데이터 분포 시프트(shift)' 가 있는데,    
  이는 프로덕션 환경의 데이터 분포가 훈련하는 동안 모델에 노출된 데이터 분포와 다르거나 괴리가 점차 커질 때 발생함.    

- 프로덕션 환경에서 동작하는 ML 모델 대부분에 영향을 미칠 만큼 만연함   




## 8.1 머신러닝 시스템 장애 원인     

- 장애는 시스템에 대한 기대치가 한가지 이상 어긋날 때 일어남   

- 전통적인 소프트웨어에서는 주로 시스템 운영에 대한 기대치,   
  즉 시스템 로직이 레이턴시와 스루풋 같은 운영 지표의 기대 범위 안에서 실행되는지가 중요함     

- ML 시스템에서는 운영 지표와 ML 성능 지표 모두 신경 써야 함     
  Ex] 영어-프랑스 기계 번역의 운영 기대치는 영어 문장을 입력하면 시스템이 바로 레이턴시 1초 안에 프랑스어 번역문을 출력해 내는 것이고,     
  ML 성능상 기대치는 출력 중 99%는 주어진 영어 문장을 정확히 번역한 문장이어야 한다는 것임.    
  출력한 번역이 정확하지 않다고 해서 반드시 시스템 장애는 아님, 정확도 기대치는 약간의 오차를 허용함.  
  하지만, 서로 다른 영어 문장을 시스템에 연달아 입력하는데 계속해서 잘못된 번역문이 나온다면 두 번째 기대치를 어기므로 시스템 장애임.   

- 운영상 기대치를 어기는 문제는 감지하기가 쉬움.   
  시간 초과, 웹 페이지 404 오류, 메모리 부족, 세그멘테이션 결함 등 운영 중단을 수반하기 때문임.  
  그러나 ML 성능상 기대치를 어기는 문제는 프로덕션 환경에서 ML 모델 성능을 측정하고 모니터링해야 하므로 감지하기가 보다 어려움.     
  영어 - 프랑스어 기계 번역 시스템 예시에서 올바른 번역문이 무엇인지 모른다면 출력된 번역문 중 99%가 옳은지 그른지 판단하기 어려움.    
  사용자가 구글 번역문이 오역임을 인지하지 못해 오역을 사용하는 사례는 셀 수 없이 많은데      
  이러한 이유로 ML 시스템은 조용히 실패(fail silently) 한다고 함.     



### <8.1.1 소프트웨어 시스템 장애>     

- 소프트웨어 시스템 장애는 ML에 속하지 않는 시스템에서 발생하는 장애임    

  [1] 의존성 장애 :    
  시스템이 의존성을 갖는 소프트웨어 패키지 혹은 코드베이스에 중단이 발생해 시스템이 중단되는 경우임    
  서드 파티가 의존성을 유지 관리 할 때 흔히 발생하며, 의존성을 유지 관리하는 서드 파티가 더 이상 존재하지 않는 경우 특히 자주 발생   

  [2] 배포 실패 :    
  배포 오류로 인한 실패.    
  모델이 현재 버전 대신 실수로 이전 버전 바이너리를 배포하거나 시스템에 특정 파일을 읽거나 쓰기 권한 없는 경우   

  [3] 하드웨어 오류 :    
  CPU나 GPU처럼 모델 배포에 사용하는 하드웨어가 제대로 작동하지 않는 경우      
  예를 들면 사용하던 CPU가 과열돼 고장남       

  [4] 다운타임 또는 충돌:     
  시스템 구성 요소가 다른 곳에 있는 서버, AWS나 호스팅 서비스에서 실행되는 경우 해당 서버가 다운되면 시스템도 따라서 다운됨     

- 소프트웨어 시스템 장애를 해결하려면 ML 기술이 아니라 전통적인 소프트웨어 엔지니어링 기술이 필요함.     
  ML 시스템 배포에도 전통적인 소프트웨어 엔지니어링 기술이 중요한 만큼 ML 엔지니어링은 보통 ML이 아닌 엔지니어링에 중점을 둠       

- 소프트웨어 시스템 장애가 만연한 이유는 업계에서 ML 도입이 아직 초기 단계이고, 따라서 ML 프로덕션 환경을 위한 도구가 한정적이고     
  아직 모범 사례가 잘 개발되거나 표준화되지 않았기 때문임   




### <8.1.2 머신러닝 한정 장애>     


- ML 한정 장애는 ML 시스템과 관련된 장애임   
  Ex] 데이터 수집과 처리에 문제가 있을 때, 하이퍼파라미터에 문제가 있을 때, 추론 파이프라인의 변경 사항이 학습 파이프라인에    
  제대로 복사되지 않았을 때(혹은 그 반대), 데이터 분포 시프트로 모델 성능이 시간에 따라 저하 될 때, 에지 케이스, 퇴행성 피드백 루프 등이 있음    
- ML 한정 장애는 전체 장애에서 차지하는 비중은 낮지만 탐지하거나 수정이 어렵고,     
  ML 시스템이 온전히 사용되지 못하게 하므로 ML이 아닌 영역의 장애보다 훨씬 더 위험함    
  일단 여기서는 모델 배포 후에 발생하는 (1) 프로덕션 데이터가 훈련 데이터와 다른 경우,    
  (2) 에지 케이스(edge case), (3) 퇴행성 피드백 루프(degenerate feedback loop) 등을 나열한다.       

(1) 프로덕션 환경 데이터가 훈련 데이터와 다른 경우     
- ML 모델을 훈련 데이터로 학습함은 모델이 훈련 데이터에 내재된 분포를 학습한 후에    
  그 학습된 분포를 통해 훈련 중 본 적 없는 데이터에 대해 정확한 예측값을 만들어냄을 의미함       
- '데이터 분포 시프트' 는 수학적으로 의미하는 바가, 모델이 본 적 없는 데이터에 대해    
  정확한 예측값을 만들어낸다면 이 모델이 '본 적 없는 데이터에도 충분히 일반화' 됐다고 얘기함    
- 개발 중 모델 평가에 사용하는 테스트 데이터는 본 적 없는 데이터여야 하며 이에 대한 모델 성능은 모델이 얼마나 잘 일반화될지 가늠하게 해줌       


- ML 교과 과정에서 먼저 배우는 것 중 하나는 훈련 데이터와 본 적 없는 데이터가 유사한 분포에서 나와야 한다는 것임    
  즉, 본 적 없는 데이터를 훈련 데이터 분포와 동일한 '정상 분포(stationary distribution)' 에서 추출했다고 가정함.    
  본 적 없는 데이터를 다른 분포에서 추출하면 모델이 제대로 일반화되지 않을 수 있음.     

  => 이 가정은 대개 올바르지 않을 수 있음.    
  첫 째로, 실제 데이터에 내재된 분포는 훈련 데이터에 내재된 분포와 같지 않을 수 있음.     
  훈련 데이터셋이 모델이 프로덕션 환경에서 접할 데이터를 정확하게 표현하도록 큐레이팅 하기는 어려움.    
  실제 데이터는 다면적이고 많은 경우에 변형이 무한에 가까운 반면, 훈련 데이터는 유한하고     
  데이터셋 생성과 처리에 사용할 수 있는 시간/연산/인적 자원에 의해 제한됨    
  다양한 종류의 선택이나 샘플링 편향이 존재함    


- 현실 데이터가 훈련 데이터와 매우 달라져서, 이러한 데이터 분포의 차이는 다른 유형의 이모티콘 인코딩을 사용하는 현실 데이터처럼    
  매우 사소한 것에 기인할 수 있음 => 이러한 유형의 차이를 훈련-서빙 편향(trin-serving skew) 이라는 흔한 장애 모드를 야기함     
  : 모델이 개발 시에는 훌륭하지만 배포 후 성능은 그다지 좋지 않은 현상     


- 둘째로, 현실 세계는 정상성(stationarity)를 갖지 않음     
  모든 것은 변하며, 데이터 분포는 시프트함   
  모델이 처음 배포될 때는 훌륭하게 작동하지만 시간에 따라 데이터 분포가 변하면서 성능이 저하됨     

- 데이터 시프트를 유발하는 예시로 코로나19 사례를 들면 사람들은 데이터 시프트     
  비정상적인 이벤트 때문에 발생한다고 생각하기 쉬워, 자주 발생하지 않는다고 생각함     
  그러나, 데이터 시프트는 항상, 갑자기, 점진적으로 혹은 계절성을 띠며 발생함     

  특정 이벤트 때문에 갑자기 발생하는 예시는 기존 경쟁자가 가격 정책을 변경해서     
  이에 대응하기 위해 가격 예측을 업데이트해야 하는 경우, 새로운 지역에서 제품을 출시하거나     
  유명인이 제품을 언급해 신규 사용자가 급증하는 경우 등이고      

  점진적으로 발생하는 예는 사회 규범, 문화, 언어, 트렌드,     
  산업과 같이 시간에 따라 변화하는 경우와 계절적 변화 때문에 발생하는 예시이다.     


- 모니터링 대시보드에서 데이터 시프트처럼 보이는 것들은 사실 대부분 내부 오류임     
- ML 시스템의 복잡성과 잘못된 배포 관행 때문인데, 데이터 파이프라인의 버그/잘못 입력된 결측값/훈련과 추론 시    
  추출한 피처 간의 불일치/잘못된 데이터 하위 집합의 통계를 적용해 표준화한 피처/잘못된 모델 버전    
  또는 사용자 행동을 바꾸게 강제한 앱 인터페이스상 버그 등이 원인이 될 수 있음    


#### (2) 에지 케이스    
- ML 모델이 대부분 잘 작동하더라도 낮은 확률로 장애가 발생해 치명적인 결과를 유발한다면 모델 사용 자체가 어려워짐     
  주요 자율 주행 자동차 회사들은 시스템이 에지 케이스에서 잘 작동하도록 하는 데 최선을 다하고 있음      

- 에지 케이스란 너무 극단적이여서 모델이 치명적인 실수를 하게 되는 데이터 샘플을 말함      
  에지 케이스는 보통 동일한 분포에서 나온 데이터 샘플이지만, 모델이 잘 작동하지 않는 데이터 샘플 수가 급증했다면    
  내재된 데이터의 분포가 시프트하지 않았나 의심해봐야 함     
- 에지 케이스가 배포된 ML 시스템을 망가뜨리는 사례로 자율 주행 자동차를 이야기 하는데,    
  안전이 중요한 모든 애플리케이션이 이러한 사례에 해당한다.     
  또한, 안전이 중요하지 않은 애플리케이션도 고객 서비스 챗봇이 문의에 대개 합리적으로 응답하지만 인종 차별적이거나    
  성차별 적인 내용을 뱉는다고 생각하면 브랜드 이미지에 좋지 않아 사용하기 어려워짐      


***에지 케이스와 이상치***

- 에지 케이스와 이상치에 대한 차이점을 살펴보면, 에지 케이스의 구성 요소에 대한 정의는 분야에 따라 다르다.      
  ML은 최근에 프로덕션 환경에 도입되기 시작해서, 에지 케이스가 계속 발견되고 있다.      
  따라서 용어 정의에 논란의 여지가 생기고 있다      
- 여기서의 이상치란 다른 데이터 포인트와 성질이 크게 다른 데이터 포인트 데이터를 의미하는데,     
  에지 케이스는 성능을 의미한다.     
- 다른 데이터 포인트보다 모델 성능이 크게 뒤떨어지는 데이터 포인트임     
- 이상치 또한 모델 성능이 비정상적으로 저조한 원이 될 수 있어 에지 케이스에 포함되기도 함      
- 다만 모든 이상치가 에지 케이스는 아님      
  Ex] 고속 도로를 무단 횡단 하는 사람이 이상치이지만,     
  자율 주행 자동차가 그 사람을 정확하게 탐지하고 그에 대한 반응을 적절하게 판단할 수 있다면 에지 케이스가 아님.   
- 모델 개발 중에 이상치가 모델 성능에 부정적인 영향을 미치기도 하는데,    
  많은 경우 모델이 더 나은 결정 경계를 학습하고 본 적 없는 데이터에 더 잘 일반화되도록 이상치를 제고하곤 함.    
  그러나, 일반적으로 추론 과정에서 다른 질의문과 성격이 크게 다른 질의문을 제거하거나 무시할 수 없음.  


#### (3) 퇴행성 피드백 루프.     

- 피드백 루프는 예측값을 제시한 다음 예측값에 대한 피드백이 되돌아올 때까지 걸리는 시간을 의미함.       

- 피드백은 자연 레이블을 추출해 모델 성능을 평가하고 다음번 훈련을 반복하는데 사용 가능함.      

- 퇴행성 피드백 루프(degenerate feedback loop)는 예측 자체가 피드백에 영향을 미치고,   
  이 피드백이 모델의 다음번 반복 학습에 영향을 미칠 때 발생함     

- 퇴행성 피드백 루프는 시스템 출력을 시스템의 미래 입력을 생성하는 데 사용할 때 발생하고,    
  이것은 시스템 미래 출력에 다시 영향을 미침     

- ML에서 시스템의 예측은 사용자가 시스템과 상호 작용하는 방식에 영향을 미침     

- 시스템과 사용자의 상호 작용은 때때로 같은 시스템에 대한 훈련 데이터로 사용되므로    
  퇴행성 피드백 루프가 발생하면서 의도하지 않은 결과를 초래할 수 있음

- 퇴행성 피드백 루프는 추천 시스템과 광고 클릭률 예측 등    
  사용자에게서 획득한 자연 레이블이 존재하지 않는 작업에서 특히 흔함

  Ex] 사용자가 좋아할 말한 노래를 추천하는 시스템을 개발한다고 가정할 때, 시스템에서 순위가 높은 노래가 사용자에게 먼저 보이게 됨.    
  가장 먼저 보이면 사용자가 더 많이 클릭하게 되고 시스템은 이 추천 항목이 적절하다고 확신하게 됨.     
  처음에는 두 곡 A와 B의 순위가 미세하게 달랐고, A가 좀 더 높은 순위에 있어서 추천 목록에 좀 더 상단에 보여지게 되었으나,    
  사용자가 잘 보이는 곳에 있는 A를 더 많이 클릭하게 되고 시스템에서 A의 순위가 B보다 올라가게 된다.   

  퇴행성 피드백 루프는 인기 있는 영화, 도서, 음악이 점점 더 인기를 얻는 이유를 설명하는 한 가지 요소이며    
  프로덕션 환경에서는 이러한 현상이 나타나는 시나리오가 매우 보편적이고 많이 연구되어 왔음.    

  => 이를 '노출 편향', '인기도 편향', '필터 거품', '에코 체임버' 등으로 불리게 됨.   

- 퇴행성 피드백 루프의 위험성은, 이력서 기반 지원자가 특정 직무에 적합한지 예측하기 위한    
  심사 모델을 개발했을 때와 같이 특정 피처 X에 높은 가중치를 부여하게 되면서 발생할 수 있음.     
  이는 모델에 대한 각 피처의 중요도를 측정하는 식으로 모델이 예측을 수행하는 방식에 대한   
  가시성을 확보하여 특정 피처에 대한 편향을 감지한다.    

- 사람이 관여하지 않으면 퇴행성 피드백 루프로 인해 모델이 최적 성능에 못 미치는 상태로 계속 동작함.    
  최악의 경우 데이터에 존재하는 편향이 영속화되고 확대됨.    
