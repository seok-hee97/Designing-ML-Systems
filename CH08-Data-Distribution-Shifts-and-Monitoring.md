# CH08 데이터 분포 시트프와 모니터링(Data Distribution Shifts and Monitoring)     

- 모델 성능은 프로덕션 환경에서 시간에 따라 저하됨   

- 모델 배포 후에도 이슈를 탐지하기 위해 성능을 지속적으로 모니터링해야 하며   
  발생한 이슈를 수정하는 업데이트를 계속 배포해야함.   
- ML 모델이 프로덕션 환경에서 실패하는 이유 중 '데이터 분포 시프트(shift)' 가 있는데,    
  이는 프로덕션 환경의 데이터 분포가 훈련하는 동안 모델에 노출된 데이터 분포와 다르거나 괴리가 점차 커질 때 발생함.    

- 프로덕션 환경에서 동작하는 ML 모델 대부분에 영향을 미칠 만큼 만연함   




## 8.1 머신러닝 시스템 장애 원인     

- 장애는 시스템에 대한 기대치가 한가지 이상 어긋날 때 일어남   

- 전통적인 소프트웨어에서는 주로 시스템 운영에 대한 기대치,   
  즉 시스템 로직이 레이턴시와 스루풋 같은 운영 지표의 기대 범위 안에서 실행되는지가 중요함     

- ML 시스템에서는 운영 지표와 ML 성능 지표 모두 신경 써야 함     
  Ex] 영어-프랑스 기계 번역의 운영 기대치는 영어 문장을 입력하면 시스템이 바로 레이턴시 1초 안에 프랑스어 번역문을 출력해 내는 것이고,     
  ML 성능상 기대치는 출력 중 99%는 주어진 영어 문장을 정확히 번역한 문장이어야 한다는 것임.    
  출력한 번역이 정확하지 않다고 해서 반드시 시스템 장애는 아님, 정확도 기대치는 약간의 오차를 허용함.  
  하지만, 서로 다른 영어 문장을 시스템에 연달아 입력하는데 계속해서 잘못된 번역문이 나온다면 두 번째 기대치를 어기므로 시스템 장애임.   

- 운영상 기대치를 어기는 문제는 감지하기가 쉬움.   
  시간 초과, 웹 페이지 404 오류, 메모리 부족, 세그멘테이션 결함 등 운영 중단을 수반하기 때문임.  
  그러나 ML 성능상 기대치를 어기는 문제는 프로덕션 환경에서 ML 모델 성능을 측정하고 모니터링해야 하므로 감지하기가 보다 어려움.     
  영어 - 프랑스어 기계 번역 시스템 예시에서 올바른 번역문이 무엇인지 모른다면 출력된 번역문 중 99%가 옳은지 그른지 판단하기 어려움.    
  사용자가 구글 번역문이 오역임을 인지하지 못해 오역을 사용하는 사례는 셀 수 없이 많은데      
  이러한 이유로 ML 시스템은 조용히 실패(fail silently) 한다고 함.     



### <8.1.1 소프트웨어 시스템 장애>     

- 소프트웨어 시스템 장애는 ML에 속하지 않는 시스템에서 발생하는 장애임    

  [1] 의존성 장애 :    
  시스템이 의존성을 갖는 소프트웨어 패키지 혹은 코드베이스에 중단이 발생해 시스템이 중단되는 경우임    
  서드 파티가 의존성을 유지 관리 할 때 흔히 발생하며, 의존성을 유지 관리하는 서드 파티가 더 이상 존재하지 않는 경우 특히 자주 발생   

  [2] 배포 실패 :    
  배포 오류로 인한 실패.    
  모델이 현재 버전 대신 실수로 이전 버전 바이너리를 배포하거나 시스템에 특정 파일을 읽거나 쓰기 권한 없는 경우   

  [3] 하드웨어 오류 :    
  CPU나 GPU처럼 모델 배포에 사용하는 하드웨어가 제대로 작동하지 않는 경우      
  예를 들면 사용하던 CPU가 과열돼 고장남       

  [4] 다운타임 또는 충돌:     
  시스템 구성 요소가 다른 곳에 있는 서버, AWS나 호스팅 서비스에서 실행되는 경우 해당 서버가 다운되면 시스템도 따라서 다운됨     

- 소프트웨어 시스템 장애를 해결하려면 ML 기술이 아니라 전통적인 소프트웨어 엔지니어링 기술이 필요함.     
  ML 시스템 배포에도 전통적인 소프트웨어 엔지니어링 기술이 중요한 만큼 ML 엔지니어링은 보통 ML이 아닌 엔지니어링에 중점을 둠       

- 소프트웨어 시스템 장애가 만연한 이유는 업계에서 ML 도입이 아직 초기 단계이고, 따라서 ML 프로덕션 환경을 위한 도구가 한정적이고     
  아직 모범 사례가 잘 개발되거나 표준화되지 않았기 때문임   




### <8.1.2 머신러닝 한정 장애>     


- ML 한정 장애는 ML 시스템과 관련된 장애임   
  Ex] 데이터 수집과 처리에 문제가 있을 때, 하이퍼파라미터에 문제가 있을 때, 추론 파이프라인의 변경 사항이 학습 파이프라인에    
  제대로 복사되지 않았을 때(혹은 그 반대), 데이터 분포 시프트로 모델 성능이 시간에 따라 저하 될 때, 에지 케이스, 퇴행성 피드백 루프 등이 있음    
- ML 한정 장애는 전체 장애에서 차지하는 비중은 낮지만 탐지하거나 수정이 어렵고,     
  ML 시스템이 온전히 사용되지 못하게 하므로 ML이 아닌 영역의 장애보다 훨씬 더 위험함    
  일단 여기서는 모델 배포 후에 발생하는 (1) 프로덕션 데이터가 훈련 데이터와 다른 경우,    
  (2) 에지 케이스(edge case), (3) 퇴행성 피드백 루프(degenerate feedback loop) 등을 나열한다.       

(1) 프로덕션 환경 데이터가 훈련 데이터와 다른 경우     
- ML 모델을 훈련 데이터로 학습함은 모델이 훈련 데이터에 내재된 분포를 학습한 후에    
  그 학습된 분포를 통해 훈련 중 본 적 없는 데이터에 대해 정확한 예측값을 만들어냄을 의미함       
- '데이터 분포 시프트' 는 수학적으로 의미하는 바가, 모델이 본 적 없는 데이터에 대해    
  정확한 예측값을 만들어낸다면 이 모델이 '본 적 없는 데이터에도 충분히 일반화' 됐다고 얘기함    
- 개발 중 모델 평가에 사용하는 테스트 데이터는 본 적 없는 데이터여야 하며 이에 대한 모델 성능은 모델이 얼마나 잘 일반화될지 가늠하게 해줌       


- ML 교과 과정에서 먼저 배우는 것 중 하나는 훈련 데이터와 본 적 없는 데이터가 유사한 분포에서 나와야 한다는 것임    
  즉, 본 적 없는 데이터를 훈련 데이터 분포와 동일한 '정상 분포(stationary distribution)' 에서 추출했다고 가정함.    
  본 적 없는 데이터를 다른 분포에서 추출하면 모델이 제대로 일반화되지 않을 수 있음.     

  => 이 가정은 대개 올바르지 않을 수 있음.    
  첫 째로, 실제 데이터에 내재된 분포는 훈련 데이터에 내재된 분포와 같지 않을 수 있음.     
  훈련 데이터셋이 모델이 프로덕션 환경에서 접할 데이터를 정확하게 표현하도록 큐레이팅 하기는 어려움.    
  실제 데이터는 다면적이고 많은 경우에 변형이 무한에 가까운 반면, 훈련 데이터는 유한하고     
  데이터셋 생성과 처리에 사용할 수 있는 시간/연산/인적 자원에 의해 제한됨    
  다양한 종류의 선택이나 샘플링 편향이 존재함   