# [CH04 훈련 데이터(Training Data)]

- 양질의 훈련 데이터를 얻거나 생성하는 기술    
- 여기서의 훈련 데이터는 ML 모델 개발 단계에서 사용하는 데이터를 모두 폴괄하며, 훈련/검증/테스트 목적으로 다양하게 분할한 데이터가 포함됨.   


- '훈련 데이터 셋'이 아닌 '훈련 데이터'라는 용어를 사용하는데, '데이터셋'은 유한하고 고정적인 집합을    
  의미하지만 프로덕션 환겨의 데이터는 유한하지도 고정적이지도 않기 때문

- 데이터는 잠재적인 편향으로 가득하다. 수집, 샘플링, 레이블링 과정에서 발생하기도 하고 과거 데이터는 사람의   
  편향을 내포할 수 있어 해당 데이터로 훈련한 ML 모델은 편향이 공고해질 수 있음.    



## <4.1 샘플링>  

- 샘플링은 매우 다양하게 사용되지만, 한가지로 가용된 전체 실데이터에 접근하기 어려운 경우,    
  모델 훈련을 위해 샘플림으로 실제 데이터의 하위 집합을 생성해 사용   
  또한 접근 권한이 있는 전체 데이터를 다루려면 시간과 자원이 너무 소모되어 데이터를 샘플링해 처리가능한 하위집합을 생성   

- 샘플링 방법을 알면 잠재적인 샘플링 편향을 피할 수 있고, 데이터의 효율성을 향상하는 샘플링 방법을 선택할 수 있다.    

- 샘플링은 크게 '비확률적 샘플링'과 '무작위 샘플링'으로 나뉨     

  - '비확률 샘플링'  
    데이터를 확률이 아닌 기준에 의거해 선택함  
  - 편의 샘플링(Convenience sampling)    
    데이터 샘플을 가용성에 의거해 선택  
  - 눈덩이 샘플링(Snowball sampling)   
    기존 샘플을 기반으로 미래샘플 선택  
    Ex] 트위터 데이터베이스에 접근하지 않고, 트위터 계정을 합법적으로 스크랩하려면 사용자 계정    
    몇 개를  임믜로 만들어 해당 계정을 팔로우하는 계정을 스크랩.  

  - 판단 샘플링(Judgement sampling)  
    전문가가 어떤 샘플을 포함할지 결정   
  - 할당 샘플링(Quota sampling)  
    무작위화(randomization) 없이 특정 데이터 그룹별 할당량에 의거해 샘플 선택.   
    Ex] 실제 연량 분포와 상관없이 설문 조사 실시시 각 연령 그룹(30세 미안,30-60세,60세 초과)마다 응답 100개씩 수집.   


- 확률이 아닌 기준으로 선택한 샘플을 실데이터를 잘 대표하지 못하고 '선택 편향'이 강함   


- ML 훈련을 위한 데이터를 선택할 때 비확률 샘플링을 사용하면 결과과 좋지 않지만 사용이 편리해서 이러한 방법을 많이 사용함.   

  Ex] 언어 모델은 수집하기 쉬운 데이터, 위키백과,커먼 크롤, 레딧 등의 데이터로 훈련하는 경우가 많은ㄷ, 가용한 전체 텍스트를 대표하지 못함.   


  일반 텍스트의 감성 분석을 위한 데이터 또한 imdb 리뷰, 아마존 리뷰 등 자연 레이블(순위)이 있는 소스에서 수집되 다른 감성 분석 작업에 적용됨.   
  그러나 이 리뷰는 온라인 리뷰를 남기는 사용자 집단에 편향되어 있고, 인터넷을 사용하지 못하거나 온라인 리뷰를 남길 의사가 없는 사람까지 대표하기 어려움.  


  또, 자율 주행 자동차 훈련 데이터는 초창기에 애리조나주 피닉스와 캘리포니아주 실리콘 밸리인 날씨가 화창한 지역에서 주로 수집했음.    
  웨이모는 우천 데이터를 확보하고나 비가 많이 오는 워싱턴주의 커클랜드로 사업을 확장했지만 여전히 비나 눈이 내리는 날씨보다 맑은 데이터가 훨씬 많음.   


- 비확룰 샘플링은 빠르고 편해 프로젝트 초창기에 데이터를 수집하고 업무를 시작하는 단계에서 사용할만 하지만,    
  신뢰성 있는 모델이라면 확률 기반 샘플링을 사용해야 함.  

  - '확률 기반 샘플링'.  
    - 단순 무작위 샘플링:
      모집단의 각 샘플이 선택될 확률이 모두 동일.  
      예를 들어 모집단의 10%를 무작위로 선태갛면 해당 모집단의 각 구성요소가 선택될 확률은 모두 10%로 동일.  
      단순 무작위 샘플링은 구현이 쉽지만, 단점이 드물게 발생하는 범주의 데이터가 포함되지 않을 수 있다는 점.   
      특정 클래스가 데이터 모집단의 0.01%로 발생한다고 생각했을 때, 데이터 1%를 무작위로 선택하면    
      위와 같이 드물게 발생하는 클래스의 샘플은 포함되지 않음    

    - 계층적 샘플링(Staratified sampling):
    모집단을 상이한 성질의 그룹으로 나눈 뒤 각 그룹에 개별적으로 샘플링을 수행해 단순 무작위 샘플링의 단점을 극복함.  
    ex] 두 클래스 A, B가 있을 때 데이터에서 1%를 샘플링하면, 클래스 A에서 1%, 클래스 B에서 1%를 각각 샘플링함  
    이렇게 하면 클래스 A,B 가 드물게 발생해도 해당 클래스의 샘플이 포함됨  
    각 그룹을 계층(STRATUM) 이라고 하고, 이러한 방법을 계층적 샘플링이라고 함  
    그러나 계층적 샘플링은 항상 가능하지 않는 단점이 있음. 모든 샘플이 원하는 그룹으로 나누는 일 자체가 불가능할 수 있는데,    
    예를 들어 다중 레이블 작업처럼 한 샘플이 여러 그룹에 속한다면 특히 까다로움.(어떤 샘플은 클래스 A와 클래스 B 양쪽에 속함)   

    - 가중 샘플링(weighted sampling):   
    각 샘플에 가중치가 있고, 이를 기반으로 샘플이 선택될 확률이 결정됨.   
    샘 A,B,C가 있고 각가 50%,30%,20% 확룰로 선택될길 원하면 가중치를 0.5, 0.3, 0.2로 정함   
    보유하고 있는 데이터가 실제 데이터 모집단과 다소 다른 분포에서 추출ㄷ괸 경우에 도움이 됨  


    Ex] 보유 데이터 샘플이 빨간색이 25% 이고 파란색이 75%인데, 실제로 데이터 모집단은 빨간색과 파란색이 발생할 확률이 동일하다면   
    빨간색 샘플이 파란색 샘플보다 3배 높은 가중치를 부여함   

    python에서 가중 샘플링은 다음과 같이 random.choices로 구현  

    ```
    # 1,2,3,4는 각각 20% 확룰로, 100, 1000은 각각 10% 확룰로,
    # 리스트에서 아이템 두 개를 선택합니다.
    import random
    random.choices(population=[1, 2, 3, 4, 100, 1000],
                   weights=[0.2, 0.2, 0.2, 0.2, 0.1, 0.1],
                   k=2)

    # 이는 다음 구문의 결과와 같습니다
    random.choices(population = [1, 1, 2, 2, 3, 3, 4, 4, 100, 1000],
                  k=2)
    ```


- 가중 샘플링과 밀접하게 관련된 ML 개념은 '샘플 가중치(sample weight)'임.    
  가중 샘플링은 모델을 훈련할 샘플을 선택하는데 사용하는 반면, 샘플 가중치는 훈련 샘플에 '가중치' 또는 '중요도'를   
  할당하는데 사용   
  샘플 가중치를 변경하면 모델의 결정 경게가 크게 변함  

  - 저수지 샘플링(reservoir sampling):
    프로덕션 환경의 스트리밍 데이터를 처리할 때 유용한 알고리즘   

    지속적으로 수집되는 트윗 스트림이 있고, 분석을 하거나 모델을 훈련하기 위해 k개의 트윗을 샘플링한다고 가정할 때,    
    특정 트윗이 선택될 확률을 미리 알 수 없는데 '각 트윗이 선택될 확률이 동일' 하고 '알고리즘 가동을 언제든지 멈출 수 있으며    
    각 트윗이 올바른 확률로 샘플링됐음을 보장' 해야 한다면?    

    => '저수지 샘플링' 으로, 배열 형태로 구현 가능한 저장소(reservoir)를 포함하여 3단계로 이뤄짐   
    (1) 첫 k개의 요소를 저장소에 넣음    
    (2) 수집되는 각 n 번째 요소마다 1<=i <=n을 만족하는 난수 i 생성   
    (3) 1<=i<=k 라면 저장소의 i번째 요소를 n번째 요소로 교체함   
    아니라면 다음 요소로 넘어감   

    수집되는 각 n번째 요소가 저장소에 포함될 확률이 k/n 이며,    
    저장소 내 각요소가 k/n의 확률로 선택되어, 각 샘플이 선택될 확률이 동일함    



  - 중요도 샘플링(importance sampling)   
    ML뿐 아니라 다양한 분야에 두루 사용되는 중요한 방법   
    이 방법을 사용하면 원하는 분포가 아닌 다른 확률 분포만 활용 가능한 상황에서도    
    원하는 확률 분포에서 샘플링을 수행할 수 있음   


    확률 분포 P(x) 에서 x를 샘플링해야 하는데 P(x)는 샘플링 비용이 크고 느리며 활용이 어려운데,     
    분포 Q(x)는 샘플링하기가 쉽다면 X를 Q(x) 에서 대신 샘플링하고, 해당 샘플의 가중 치를 P(x)/Q(x)로 부여함.    

    Q(X)를 제안 분포(proposal distribution) 또는 중요도 분포(importance distribution) 이라고 부름.     

    Q(x)는 P(x) != 0인 경우 Q(X) > 0을 만족하는 임의의 분포로 정함    



    ML 에서 중요도 샘플링을 사용하는 사례는 정책 기반 강화 학습(policy-based reinforcement learning)임.    
    정책을 업데이트 하는 경우, 새로운 정책의 가치 함수를 추정하고 싶지만 행동에 따르는 총 보상을 계산하는 일은     
    비용이 크기 때문에(행동 후 정해진 시간만큼 기다리고 발생 가능한 결과를 모두 고려해야 하므로),     
    새로운 정책이 이전 정책과 유사하다면 이전 정책을 기반으로 총 보상을 계산하고 새로운 정책에 따른 가중치로 재조정하여, 이전 정책의 보상으로 제안 분포를 구성함




## <4.2 레이블링>   


- 비지도 ML의 장점에도 프로덕션 환경 내 ML 모델은 대부분 지도 학습 기반이다.   
  학습 용도로 레이블한 데이터가 필요해서, ML 모델의 성능은 여전히 학습 용도로 지정한 데이터의 양과 질에 크게 의존한다.    


#### <래아불 다중성>   
- 서로 다른 데이터 소스와 어노테이터가 지닌 정확도 수준은 상이해서 레이블 모호성,    
  레이블 다중성 문제, 즉 데이터 포인트에 상충하는 레이블이 복수로 존재하는 상황이 야기됨   
- 요구되는 도메인 전문 지식이 높을수록 불일치하게 레이블링 할 가능성이 커짐.   
- 어노테이터 간의 불일치를 최소화하기 위해 먼저 문제를 명확히 정의해야 함.  


#### <데이터 계보>   
- 서로 다른 어노테이터가 생성한 다양한 소스의 데이터를 품질에 대한 고민 없이 사용하면 모델에 알 수 없는 문제가 발생함
 
- 각 데이터 샘플과 레이블의 출처를 추적 가능하도록 설정하는 것을 '데이터 계보(data lineage)' 라고함   
- 데이터 계보는 데이터 내 잠재 편향에 플래그를 할당하고 모델을 디버깅하는데 도움을 줌.  


#### <자연 레이블>   

- 자연적인 그라운드 트루스 레이블이 존재하면 모델 예측을 자동으로 평가하거나 시스템상에서 부분적으로 평가할 수 있음  
  
  예를 들어, 구글 지도에서 특정 경로의 도착 시간을 추정하는 모델과 주가 예측

- 자연 레이블이 존재하는 작업은 대표적으로 추천 시스템으로, 추천 시스템의 목표는 사용자와 연관된 항목을 추천해주는 것임   
  사용자가 추천받은 항목을 클릭하는지 여부가 해당 추천에 대한 '피드백'으로 간주됨   
  클릭한 추천은 적합한 것으로 레이블 양성, 일정 시간이 지나도 클릭하지 않는 추천은 레이블이 음성   

- 많은 작업은 추천 방식으로 구조화할 수 있는데, 광고 클릭률을 예측하는 작업을   
  예로 들면 사용자의 활동 기록과 프로필을 기반으로 가장 연관성 높은 광고를 추천하는 작업으로 구조화하여,    
  클릭과 평점처럼 사용자 행동에서 추론하는 자연 레이블을 행동 레이블(behavioral label) 이라고 함   

- 작업에 자연 레이블이 없더라도 모델에 대한 피드백을 수집하게끔 시스템을 설정하는데, 구글 번역 같은 기계 번역 시스템을 개발하여,   
  사용자 커뮤니티에서 다른 번역을 제출할 수 있는 옵션을 마련하여 제안된 번역의 품질을 검토해 모델의 다음번 반복 학습에 사용한다.   

- 업계에서는 자연 레이블로 작업하는 경우가 흔함

- 위에서 일정 시간이 지나도 클릭하지 않는 추천은 좋지 못한 것으로 간주해서 이러한 음성 레이블은    
  양성 레이블의 부재를 통해 추정하여 '암시적 레이블(implicit label)' 이라고 함
  - 사용자가 추천 항목에 낮은 평점을 부여하거나 거부를 표해서 명시적으로 피드백을 주는 '명시적(explicit label)'



#### <피드백 루프 길이>   
- 자연적인 그라운드 트루스 레이블이 존재하는 작업에서, 예측을 수행하는 시점부터   
  피드백을 얻는 시점까지 걸리는 시간을 '피드백 루프 길이(feedback loop length)'라고 함   

- 피드백을 포착할 윈도 길이(window length)를 적절히 결정하려면 고민이 필요한데,   
  속도와 정확도 사이에 트레이드오프가 있기 때문이다.

- 윈도 길이가 짧으면 레이블을 더 빨리 얻을 수 있고, 레이블을 이용해 모델의 문제를 조기에 발견하고 빠르게 해결할 수 있지만   
  추천을 클릭하기 이전 너무 이른 시점에 사용자가 클릭하지 않아서 레이블을 잘못 지정해줄 수 있음   



#### <레이블 부족 문제 해결>     

- 고품질 레이블을 충분히 얻기는 어려워, 이를 해결하기 위해 약한 지도 학습(weak supervision),   
  준지도 학습(semi-supervision), 전이 학습(transfer learning), 능동적 학습(active learning)   


  - 약한 지도 학습(weak supervision) :   
  레이블을 생성하기 위해 (때때로 잡음이 있는) 휴리스틱 활용. 그라운드 트루스는 필요하지 않지만,   
  휴리스틱 개발의 기준을 삼기 위해 레이블을 적게나마 갖추기를 권장
  - 준지도 학습(semi-supervision) :    
  구조적인 가정을 활용해 레이블을 생성함.     
  그라운드 트루스가 필요하고 레이블을 추가로 생성하기 위한 시드로써 초기에 수집한 레이블이 조금 필요함.   
  - 전이 학습(trnasfer learning):    
  다른 작업에서 사전 훈련한 모델을 새로운 작업에 활용함.   
  제로샷 학습이라면 그라운드 트루스가 필요 없으나, 미세 조정이라면 그라운드 트루스가 필요하다.    
  다만 모델을 밑바닥부터 훈련할 때부터 보통은 훨씬 적게 필요함.   
  - 능동적 학습(active learning) :    
  모델 입장에서 가장 유용한 데이터 샘플을 레이블링하고, 그라운드 트루스가 필요함.   



#### 약한 지도학습(Weak supervision)   

- 수작업 레이블이 문제라면 아예 사용하지 않는 방법도 있음   

- 약한 지도 학습은 데이터를 레이블링할 때 도메인 전문 지식을 통해 개발된 휴리스틱을 활용함   
  예를 들어, 의사가 다른 휴리스틱을 이용해 환자를 위급하다고 판단해 우선시할지 결정함   
  [간호사 노트에 폐렴 같은 심각한 상태가 언급되면 해당 환자를 우선적으로 고려한다]    

- 스노클 같은 라이브러리는 '레이블링 함수(labeling function(LF)' 개념을 기반으로 개발됨    
- LF는 휴리스틱을 인코딩한 함수임    

```
def labeling_function(note):
  if "페렴" in note:
    return "위급"

```

- LF로 다양한 유형의 휴리스틱을 인코딩할 수 있음
  - 키워드 휴리스틱, 정규 표현식, 데이터베이스 조회 ,다른 모델의 출력


- LF를 작성한 후 레이블링하려는 샘플에 적용하는데, LF는 휴리스틱을 인코딩하고,    
  휴리스틱에는 잡음이 존재해서 LF가 생성한 레이블에는 잡음이 수반됨   


한 휴리스틱이 다른 휴리스틱보다 훨씬 정확하더라도 비교할 그라운드 트루스 레이블이 없어 사실을 인지하지 못해서,    
레이블이 올바를 가능성이 높은 집합을 얻으려면 모든 LF를 결합하고 잡음을 제거한 뒤 가중치를 재조정함.   


- 이론상 약한 지도 학습에는 수작업 레이블이 필요 없지만,  
  LF가 얼마나 정확한지 파악하려면 약간의 수작업 레이블을 이용하는 편이 좋음   
  수작업 레이블은 데이터에서 패턴을 발견해 LF를 더 잘 작성하는데 도움이 됨    

- 약한 지도 학습은 데이터에 개인 정보 보호 요구 사항이 엄격하게 적용될 때 유용함.  
  일부 데이터만 확인해 LF를 작성한 뒤 해당 함수를 나머지 데이터에 비공개로 적용함.  

- LF를 사용하면 도메인 전문 지식에 버전을 지정하고 그것을 재사용하거나 공유한다.    
  어떤 팀이 보유한 전문 지식을 인코딩하면 다른 팀에서도 사용가능하며,     
  데이터나 요구사항이 변경되면 데이터 샘플에 LF만 재적용하면 됨.   

- LF를 사용해 데이터 레이블을 생성하는 접근법을 '프로그래밍 방식 레이블링'이라고 함

- 휴리스틱으로 레이블링을 잘할 수 있지만, ML 모델이 필요한 이유는 LF가 데이터 샘플 전체를 다루지 못할 수 있기 때문이다.    
  LF가 제대로 다루지 못하는 샘플에 예측을 수행하려면 LF 프로그래밍 방식으로 레이블링한 데이터로 ML 모델을 훈련하고 샘플에 해당 모델을 적용한다.    

- 약한 지도 학습으로 얻은 레이블은 실제로 적용하기에 잡음이 너무 많을 수도 있음.   



#### 준지도 학습(Semi-supervision)   

- 약한 지도 학습이 휴리스틱을 이용해 잡음 섞인 레이블을 얻는다면,    
  준지도 학습 구조적인 가정을 활용해 초기에 수집한 소수의 레이블을 기반으로 새로운 레이블을 생성함   

- 약한 지도학습과 달리 초기에 수집한 레이블 집합 필요


- 대표적인 준지도 학습은 자가 훈련(self-training)으로, 레이블이 지정된 기존 데이터로 모델 학습을 시작한 뒤 해당 모델로 레이블이 미지정된 샘플에 예측을 수행함   
  떤 샘플의 원시 확률 점수가 높다면 예측이 정확하다고 가정하고, 높은 확률로 예측한 레이블을 훈련 세트에 추가하고 확장한 훈련 세트로 신규 모델을 훈련한다.     
  모델 성능이 만족스러워질 때 까지 과정 반복.   

- 다른 준지도 학습 방법은 유사한 특성이 있는 데이터 샘플끼리는 레이블이 동일하다고 가정하는 것으로,    
  트위터 해시태그 주제 분류 작업에서 해시태그 사이의 유사성을 사용하는 것이다.    
  예를 들어 해시태그 #AI에 '컴퓨터 과학' 이라는 label을 지정하고,    
  같은 트윗이나 프로필에 함께 사용된 해시태그끼리 주제가 같다고 가정하면 #ml과 #bigdata 도 '컴퓨터 과학' 이라는 label을 지정한다.     

- 대부분의 유사성을 찾으려면 클러스터링이나 k-최근접 이웃 알고리즘으로 동일한 클러스터에 속하는 샘플을 찾아냄.   


- 최근 몇년 간은 교란(perturbation) 기반 준지도 학습 방법인,     
  샘플에 작은 교란 신호를 더했을 때 레이블이 변하면 안된다는 가정에 기초하는 방식이 인기 있었음.    
  훈련 대상 샘플에 작은 교란 신호를 더해 새로운 훈련 대상 샘플을 얻는데,     
  교란 신호는 샘플에 직접 적용하거나(이미징에 백색 잡음 추가), 샘플 표현(단어 임베딩에 작은 무작위 값 추가) 에 적용한다.    
  교란 신호를 적용한 샘플과 미적용한 샘플은 레이블이 같음.   

  일부 사례에서는 데이터셋 레이블의 상당수를 삭제해도 준지도 방법의 성능이 지도 학습 성능에 버금감.   


- 준지도 학습은 훈련할 레이블 개수가 제한적일 때 가장 유용한데,    
  제한된 데이터로 준지도 학습을 수행할 때는 여러 후보 모델을 평가하고 최적 모델을 선택하려면 제한된 데이터 중 얼마나 사용할지를 고려해야 한다.     

- 적은 양을 사용하면 가장 성능이 높다고 나온 모델이 과적합 됐을 수도 있고,     
  많은 양을 사용하면 평가 세트 기반으로 최적 모델을 선택해 얻는 성능 향상의    
  폭이 한정된 훈련 세트에 평가 세트를 추가해서 얻는 성능 향상이 폭보다 작을 수 있음   
  이런 트레이드 오프를 해결하기 위해 합리적인 크기의 평가 세트로 최적 모델을 선택해 평가 세트를 합쳐 '챔피언 모델'을 한 번 더 훈련함.   


#### 전이 학습(transfer learning)    

- 전이 학습은 특정 작업을 위해 개발한 모델을 시작점으로 삼아 후속 작업에 재사용하는 일련의 방법론임.   

- 기본적인 작업(일반적으로 훈련 데이터 양이 많고 수집 비용이 낮은 작업)을 대상으로 기본 모델을 학습한다.

- 언어 모델의 작업은 토큰 시퀀스가 주어질 때 다음에 나올 토큰을 예측하는 것임   
  훈련한 모델을 관심 있는 downstream 작업 (감성 분석, 의도 감지, 질의응답)등에 사용함   
  제로샷 학습 시나리오처럼, 경우에 따라 다운스트림 작업에 모델을 직접 사용하는데,   
  기본 모델은 보통 미세 조정(fine-tuing)이 필요함.  
  미세 조정(fine-tuning)은 주어진 다운스트림 작업의 데이터로 기본 모델 혹은 그 일부에 훈련을 계속 이어나가는 등 기본 모델을 일부 변경하는 것)


- 전이 학습은 레이블링 데이터가 많지 않은 작업에 특히 적합해,    
  레이블링된 데이터가 많은 작업이어도 사전 훈련된 모델을 사용하면 
  처음부터 모델을 직접 훈련하는 것보다 성능이 큰 폭으로 향상됨



### 능동적 학습(Active learning)    

- 능동적 학습은 데이터 레이블링 작업의 효율성을 향상함   
  
- ML 모델이 학습할 데이터 샘플을 선택할 수 있다면 더 적은 학습 레이블로 더 높은 정확도를 달성할 수 있다.   

- 능동적 학습자인 모델이 레이블링되지 않은 샘플에 대해 질의하면 어노테이터(보통 사람)가 레이블을 지정함    

- 능동적 학습은 질의 학습이라고 함   

- 데이터 샘플을 무작위로 골라 레이블링 하는 대신 특정 지표나 휴리스틱에 근거해 모델에게 가장 필요한 샘픙르 선택해 레이블링한다

- 가장 간단한 측정 지표는 불확실성으로, 모델의 불확실성이 가장 높은 데이터 포인트들을 선택하고 레이블링해 모델이 결정 경계를 더 잘 학습시키도록 도움  

  예를 들어, 모델이 여러 클래스의 원시 확률을 출력하는 분류 문제라면 예측한 클래스에 대해 가장 낮은 확률을 갖는 데이터 샘플을 선택함  

  (1) 클래스가 2개인 가우스 함수에서 균일하게 샘플링한 데이터 포인트 400개로 연습용 데이터셋을 만듦  
  (2) 샘플 30개를 무작위로 선택하고 레이블링해 모델을 훈련하면 정확도가 70% 
  (3) 샘플 30개를 능동적 학습으로 선택해 모델을 훈련하며내 정확도가 90%  


- 다른 방법으로 다양한 후보 모델 간의 불일치를 기반으로 하는 휴리스틱도 사용하는데,  
  '위원회에 의한 질의(query-by-committee)라고 하며, 앙상블 방법이다.    
  다양한 후보 모델로 구성한 committee를 필요로 하는데, 이 committee는 보통 같은 모델을 서로 다른 하이퍼파라미터 집합으로 훈련한 것    
  또는 같은 모델을 서로 다른 부분으로 훈련한 것임.  
  각 모델은 다음으로 어떤 샘플을 레이블링할지 투표할 수 있으며, 이 투표는 각 모델의 예측 불확실성에 근거한다.   
  committee의 불일치 정도가 가장 큰 샘플을 선택해 레이블링함   

- 그 외에도 훈련했을 때 그래디언트 업데이트가 가장 크거나 손실을 가장 크게 줄일 수 있는 샘플을 선택하는 휴리스틱이 있다.

- 레이블링할 샘플은 다양한 데이터 구도에서 생성되어, 어떤 연구에서는 모델의 불확실성이 가장 높은 입력 공간 영역에서 샘플을 생성하는 식으로 합성 샘플을 만든다.   

- 혹은 레이블이 없는 데이터가 다수 있고, 이 데이터가 정상 분포를 가질 때 여기서 샘플링을 해 레이블링한다  

- 프로덕션 환경에서 데이터 스트림의 원천인 실제 세계 확률 분포가 존재할 때 모델은 흘러들어오는 데이터 스트림에서 레이블링할 샘플을 선택하기도 한다.    



## <4.3 클래스 불균형 문제>

- 클래스 불균형은 분류 작업에서 나타나는 문제로, 훈련 데이터 내 클래스당 샘플의 개수가 크게 차이나는 문제이다.   

- 클래스 불균형은 레이블이 연속 값인 회귀 작업에서도 발생한다.  
  모델 훈련시 전반적인 지표가 하락해도 95번째 백분위수 값을 더욱 잘 예측하도록 해야함  


#### <클래스 불균형 문제의 어려윰>   

- ML, 특히 딥러닝은 데이터 분포가 균형을 이룰 때 잘 작동하고 클래스 불균형이 심할 때는 잘 작동하지 않음   

- 클래스 불균형일 떄 학습이 어려운 이유는   
  (1) 모델이 소수 클래스를 찾아내는 법을 학습하기에 신호가 충분치 않음  
  소수 클래스의 데이터 개수가 적어서 해당 클래스를 몇 번 못본 채 판단을 내려서 퓨샷 학습 문제가 되버림   
  드물게 발생하는 데이터 포인트가 훈련 세트에 아예 포함되지 못하면 모델은 클래스가 존재하지 않는다고 가정함   
  (2) 모델이 데이터에 내재된 유용한 학습 패턴을 학습하는 대신 단순 휴리스틱을 활용하려는 경향이 강해져, 최적이 아닌 해를 고집하게 됨   
  (3) 클래스 불균형은 주로 비대칭적인 오차 비용 문제로 이어짐.   
  드물게 발생하는 클래스 샘플에 예측을 잘못해서 발생하는 비용은 다수 클래스 샘플에 예측을 잘못해 발생하는 비용보다 훨씬 큼    
  - 예를 들어, 폐암 탐지 예시에서는 암세포가 있는 엑스레이 이미지를 오분류 하면 정상 폐 이미지를 오분류할 때보다 훨씬 치명적인 겨로가가 따라서,    
    손실 함수가 이런 비대칭을 해결하도록 구성   하지 않으면 모델은 모든 샘플을 같은 방식으로 처리한다.
  그래서, 다수 클래스에서 성능이 떨어지더라도 소수 클래스에서 성능이 좋은 모데링 훨씬 선호됨

- 클래스 불균형은 실생활 애플리케이션에 만연해, 불균형 정도에 따라 작업에 주는 영향이 다르다.    

- 불균형에 대한 민감도가 문제 복잡도에 따라 증가하고,    
  복잡도가 낮고 선형으로 분리 가능한 문제는 클래스 불균형 정도에 상관없이 영향받지 않는 사실을 증명함.   


- 클래스 불균형의 영향을 완화하기 위해 많은 기법이 제안됐는데,    
  신경망이 크고 깊어질 수록 학습 능력이 향상됨에 따라 클래스 불균형을 일부러 '수정' 해서는 안된다고 말하기도 한다.    
  그 불균형이 데이터가 실제로 나타나는 모습이라면, 불균형을 모델링하는 법을 학습해야 한다.


#### <클래스 불균형 처리>  

- 클래스 불균형을 처리하는 세 가지 접근법은 (1) 문제에 적절한 지표를 선택 (2) 데이터 수준의 방법으로    
  데이터 분포를 변경해 불균형 정도를 낮추는 방법 (3) 학습 방법을 클래스 불균형에 더 강건해지도록 변경하는 방법이다.

  - 올바른 평가 지표 사용하기
    전제 정확도와 오차 비율은 ML 모델 성능을 보고하는데 자주 사용하는 지표인데,    
    이 지표는 모든 클래스를 동일하게 취급하여 클래스 불균형이 있는 작업네는 적절하지 않음.   

    정밀도, 재현율, f1은 비대칭 지표로, 어떤 클래스를 양성 클래스로 간주할지에 따라 값이 바뀜.    

    분류 문제 중 다수는 회귀 문제로 모델링할 수 있는데, 모델이 확률을 출력하면 해당 확률 기반으로 샘플을 분류.  


  - 데이터 수준의 방법: 리샘플링
    훈련 데이터 분포를 수정해 불균형 정도를 줄여 모델 학습을 용이하게 만든다.    
    리샘플링은 다수 클래스에서 데이터 포인트를 제거하는 언더샘플링과, 소수 클래스로부터 데이터 포인트를    
    추가하는 오버 샘플링이있다.     

    가장 간단한 언더샘플링은 다수 클래스에서 데이터 포인트를 무작위로 제거하고,   
    가장 간단한 오버샘플링은 원하는 비율이 될 때까지 소수 클래스 복사본을 무작위로 생성한다.      

    저차원 데이터를 언더샘플링하는 방법은 토멕(tokmek) 링크가 인기 있다.      
    서로 반대되는 클래스에서 근접한 샘플 쌍을 찾아 각 쌍에서 다수 클래스의 샘플을 제거하는데,        
    결정. 경계가 명확해저 모델이 경계를 학습하는 데는 도움이 되지만,       
    실제 결정 경계의 미묘한 형태를 학습하지 못해 모델의 강건성이. 떨어짐.      


    저차원 데이터를 오버샘플링하는 바업은 소수 클래스 합성을 통한 오버샘플링으로   
    SMOTE(Synthetic Minority Over-sampling Technique)으로,        
    소수 클래스 내의 기존 데이터 포인트에 대한 볼록 조합(convex combination) 샘플링으로.     
    소수 클래스의 새로운 샘플을 합성함      

    토멕 링크와 smote 모두 저차원 데이터에서만 효과적으로, 니어-미스(near-miss)나 단측 선택 같이 정교한 리샘플링   
    기법은 대부분 데이터 포인트 사이 혹은 데이터 포인트와 결정 경계 사이의 거리를 계산해야 하고,     
    이러한 연산은 대형 신경망처럼 고차원 데이터 또는 고차원 피처 공간에서 비용이 너무 크거나 실행이 불가능함.      

    훈련 데이터를 리샘플링하면 리샘플링된 데이터에서 모델을 평가하지 말아야하는데,        
    리샘플링한 분포에 과적합될 수 있기 떄문이다.     

    언더샘플링은 데이터 제거 과정에서 중요 데이터가 손실됨 위험과,    
    오버샘플링은 훈련 데이터에 과적합될 위험이 있다.      

    => 이를 완화하기 위해 2단계 학습이나오는데, 먼저 리샘플링한 데이터로 모델을 훈련해서,     
    여기에 리샘플링 데이터는 각 클래스에 데이터 포인트가 N개만 남을 때까지      
    다수 클래스를 무작위로 언더 샘플링해서 만들고, 원래 데이터로 모델을 미세 조정한다.    


    또한, 동적 샘플링으로 학습 과정에서 성능이 낮은 클래스를 오버샘플링하고 성능이 높은 클래스를 언더 샘플링한다.    
    모델에게 이미 학습한 것보다 학습하지 않은 것을 더 많이 보여주면서 학습하는 방법이다.     

    - 알고리즘 수준의 방법
    데이터 수준의 방법이 학습 데이터 분포를 변경해 클래스 불균형 문제를 해결하려는 반면 알고리즘 수준의 방법은,     
    학습 데이터의 분포를 그대로 유지하면서 클래스 불균형에 강건한 알고리즘으로 변경하는 것이다.      

    - 알고리즘 수준의 방법은 대부분 학습 프로세스를 지도해나가는 손실 함수(비용함수)를 조정한다.      

      두 데이터 포인트 x1, x2가 있을 때 x1 예측을 잘못해 발생하는 손실이 x2보다 크다면,    
      모델은 x2보다 x1을 올바르게 예측하는 일을 우선시해야 한다. 우선시 하는 훈련 데이터 포인트에     
      가중치를 더 크게 부여하면 모델은 해당 데이터 포인트를 학습하는데 더 초점을 맞춤.     

      L(x:Θ)를 매개변수 집합 Θ 가 있는 모델에 대해 데이터 포인트 x로 인한 손실이라고 가정할 때,    
      모델 손실은 보통 모든 데이터 포인트로 인한 평균 손실로 정의한다     

      L(X;Θ) = Σ(1/N) * L(x;Θ)

      이 손실함수는 일부 데이터 포인트를 잘못 예측했을 때 비용이 다른 데이터 포인트보다     
      훨씬 크더라도 데이터포인트로 인한 손실을 모두 동일하게 평가한다.     

      이러한 비용 함수를 수정하는 방법은     
      (1) 비용 민감 학습, (2)클래스 균형 손실, (3)초점 손실 등이 있다.      


    - 비용 민감 학습
      클래스마다 오분류 비용이 다르므로, 서로 다른 비용을 고려해 각 손실 값을 수정함    
      클래스의 데이터 포인트로 인한 손실은 데이터 포인트의 모든 가능한 분류의 가중 평균이 됨    
      이 손실함수의 문제점은 비용 행렬을 수작업으로 정의해야함  


    - 클래스 균형 손실:
      불균형 데이터셋으로 훈련한 모델은 다수 클래스로 편향되고,     
      소수 클래스에서 예측을 잘 못하기 떄문에 소수 클래스를 잘못 예측한 모델에게 불이익을 줌   

      기본적인 형태로 각 클래스의 가중치를 해당 클래스 샘플 수에 반비례 하게 만들어,       
      더 적은 수의 클래스가 큰 가중치를 갖게 함       

      손실 함수는 교차 엔트로피 등으로, 보다 정교하게 유효 샘플 수 기반의 클래스 균형 손실처럼   
      샘플 간의 중첩을 고려함.   

    - 초점 손실(Focal loss).  
      데이터에서 어떤 데이터 포인트는 다른 것들보다 분류하기 쉽고, 모델은 이런 데이터 포인트를    
      분류하는 방법을 빠르게 습득한다.    
      모델이 분류하기 어려운 샘플을 집중적으로 학습하도록 인센티브를 주는데, 예측이 맞을 확률이 낮을수록   
      샘플 가중치가 커지도록 손실을 조정한다.   

    - 실전에서는 앙상블이 클래스 불균형 문제에 큰 효과를 보이지만, 일반적으로 앙상블을 사용하는 이유는    
      클래스 불균형 때문은 아니다.


# <4.4 데이터 증강>      
- 데이터 증강은 훈련 데이터 양을 늘리는 기법.   

- 증강 데이터는 모델이 잡음과 적대적 공격(adversarial attack)에 강건해지게 한다.   

- 데이터 증강의 유형으로 (1) 단순 레이블 보존 변환, (2) '잡음을 추가'하는 교란, (3) 데이터 합성이 있다.


  - 단순 레이블 보존 변환:    
    컴퓨터 비전에서는 레이블을 유지한 채 이미지를 무작위로 자르기 ,뒤집기, 회전, 반전, 지우기 등으로 수정한다.    
    nlp에서는 일부 단어를 유사한 단어로 무작위로 대체한다. 대체해도 문장의 의미나 감정을 바꾸지 않는다고 가정하고   
    유사한 단어는 동의어 사전을 사용하거나, 단어 임베딩 공간에서 임베딩이 유사한 단어를 검색해 찾는다.    


  - 교란:     
    교란 또한 레이블을 보존하지만 종종 모델이 잘못된 예측을 하도록 한다.   
    신경망은 잡음에 민감해서 컴퓨터 비전에서는 이미지에 잡음을 소량만 추가해도 신경망이 이미지를 잘못 분류할 수 있다.  
    속임수가 있는 데이터를 사용해 신경망이 잘못된 예측을 하도록 속이는 것을 적대적 공격이라고 하고,    
    샘플에 잡음을 추가하는 것은 적대적 샘플을 생성하는 일반적인 기법이다.    
    적대적 공격은 특히 비전에서 이미지 해상도가 높은 경우 성공의 효과가 두드러짐.   

    훈련 데이터에 잡음 샘플을 추가하면 모델이 학습한 결정 경계에서 약점을 인식하고 성능을 개선하는 데 도음이 된다.   

    그러나, 적대적 증강은 nlp에서 잘 사용되지 않는다. 임의의 문장에서 임의의 문자를 추가하면 헛소리처럼    
    보일 가능성이 높기 때문이다.     
    모델을 보다 강건하게 만드는 방법으로 교란을 사용하는데 BERT에서는 모델이 각 시퀀스의 전체 토큰에서 15%를   
    무작위로 선택하고 그중 10%를 다시 선택해 임의의 단어로 대체.    

    예를 들어 '우리 집 강아지는 복슬복슬해'라는 문장이 주어졌을 때 모델이 무작위로 '복슬복슬해'를 '사과야'로 바꾸면   
    '우리 집 강아지는 사과야'가 되고, 전체 토큰의 1.5%는 무의미한 것이 된다.    
    이러한 문장의 일부를 무작위로 교체하는 것은 모델의 성능을 약간 향상한다.    

  - 데이터 합성
    :데이터 수집은 느리고 비용이 크고 개인 정보 보호 문제가 있어서,    
    합성 데이터로 모델을 훈련할 수 있는 방법도 있다.     

    모든 훈련 데이터를 합성하는 방식은 요원하더라도 일부 훈련 데이터를 합성해   
    모델 성능을 높일 수는 있습니다.   

    NLP에서는 탬플릿을 사용해 낮은 비용으로 모델을 부트스트랩 할 수 있는데, 대화형 AI(챗봇)을 위한   
    훈련 데이터를 부트스트탭하기 위해 탬플릿을 사용할 수 있다.   

    예를 들어 탬플릿 형식은 '[위치]에서 [숫자]마일 이내에 있는 [세계] 음식점을 찾아주세요.'면,     
    가능한 요리와 합리적인 숫자와 각 도시 위치를 사용해 탬플릿으로 훈련용 질의문 수천개를 생성.    


### <4장 요약>  

- 오늘날 사용하는 ML 알고리즘은 대부분 지도 학습 ML 알고리즘으로,    
  레이블 습득은 훈련 데이터를 생성하는데 필수적임.   

- 자연 레이블은 획득하는데 시간이 걸리는데, 예측 시점부터 그에 대한 피드백이 제공되기 까지 걸리는 시간을   
  피드백 루프 길이라고함

- 자연 레이블이 없는 작업이라면 기업은 데이터에 레이블링하기 위해 어노테이터에 의존하는 경향이 있는데,   
  수작업 레이블링은 느리고 비용이 크다는 단점이 있음    

- 이러한 단점을 약한 지도 학습, 준지도 학습, 전이 학습, 능동적 학습 등으로 보완함.   
  
- ML 알고리즘은 데이터 분포가 균형을 이루는 상황에서 잘 작동하고 클래스 불균형이 심하면 잘 작동하지 않는데,    
  클래스 불균형은 현실 세계에 만연함.   

- 이러한 클래스 불균형은 올바른 지표를 선택하고, 데이터 리샘플링과 모델이 특정 샘플에 집중하도록   
  손실 함수를 수정해서 처리함   
