# [CH04 훈련 데이터(Training Data)]

- 양질의 훈련 데이터를 얻거나 생성하는 기술    
- 여기서의 훈련 데이터는 ML 모델 개발 단계에서 사용하는 데이터를 모두 폴괄하며, 훈련/검증/테스트 목적으로 다양하게 분할한 데이터가 포함됨.   


- '훈련 데이터 셋'이 아닌 '훈련 데이터'라는 용어를 사용하는데, '데이터셋'은 유한하고 고정적인 집합을    
  의미하지만 프로덕션 환겨의 데이터는 유한하지도 고정적이지도 않기 때문

- 데이터는 잠재적인 편향으로 가득하다. 수집, 샘플링, 레이블링 과정에서 발생하기도 하고 과거 데이터는 사람의   
  편향을 내포할 수 있어 해당 데이터로 훈련한 ML 모델은 편향이 공고해질 수 있음.    



## <4.1 샘플링>  

- 샘플링은 매우 다양하게 사용되지만, 한가지로 가용된 전체 실데이터에 접근하기 어려운 경우,    
  모델 훈련을 위해 샘플림으로 실제 데이터의 하위 집합을 생성해 사용   
  또한 접근 권한이 있는 전체 데이터를 다루려면 시간과 자원이 너무 소모되어 데이터를 샘플링해 처리가능한 하위집합을 생성   

- 샘플링 방법을 알면 잠재적인 샘플링 편향을 피할 수 있고, 데이터의 효율성을 향상하는 샘플링 방법을 선택할 수 있다.    

- 샘플링은 크게 '비확률적 샘플링'과 '무작위 샘플링'으로 나뉨     

  - '비확률 샘플링'  
    데이터를 확률이 아닌 기준에 의거해 선택함  
  - 편의 샘플링(Convenience sampling)    
    데이터 샘플을 가용성에 의거해 선택  
  - 눈덩이 샘플링(Snowball sampling)   
    기존 샘플을 기반으로 미래샘플 선택  
    Ex] 트위터 데이터베이스에 접근하지 않고, 트위터 계정을 합법적으로 스크랩하려면 사용자 계정    
    몇 개를  임믜로 만들어 해당 계정을 팔로우하는 계정을 스크랩.  

  - 판단 샘플링(Judgement sampling)  
    전문가가 어떤 샘플을 포함할지 결정   
  - 할당 샘플링(Quota sampling)  
    무작위화(randomization) 없이 특정 데이터 그룹별 할당량에 의거해 샘플 선택.   
    Ex] 실제 연량 분포와 상관없이 설문 조사 실시시 각 연령 그룹(30세 미안,30-60세,60세 초과)마다 응답 100개씩 수집.   


- 확률이 아닌 기준으로 선택한 샘플을 실데이터를 잘 대표하지 못하고 '선택 편향'이 강함   


- ML 훈련을 위한 데이터를 선택할 때 비확률 샘플링을 사용하면 결과과 좋지 않지만 사용이 편리해서 이러한 방법을 많이 사용함.   

  Ex] 언어 모델은 수집하기 쉬운 데이터, 위키백과,커먼 크롤, 레딧 등의 데이터로 훈련하는 경우가 많은ㄷ, 가용한 전체 텍스트를 대표하지 못함.   


  일반 텍스트의 감성 분석을 위한 데이터 또한 imdb 리뷰, 아마존 리뷰 등 자연 레이블(순위)이 있는 소스에서 수집되 다른 감성 분석 작업에 적용됨.   
  그러나 이 리뷰는 온라인 리뷰를 남기는 사용자 집단에 편향되어 있고, 인터넷을 사용하지 못하거나 온라인 리뷰를 남길 의사가 없는 사람까지 대표하기 어려움.  


  또, 자율 주행 자동차 훈련 데이터는 초창기에 애리조나주 피닉스와 캘리포니아주 실리콘 밸리인 날씨가 화창한 지역에서 주로 수집했음.    
  웨이모는 우천 데이터를 확보하고나 비가 많이 오는 워싱턴주의 커클랜드로 사업을 확장했지만 여전히 비나 눈이 내리는 날씨보다 맑은 데이터가 훨씬 많음.   


- 비확룰 샘플링은 빠르고 편해 프로젝트 초창기에 데이터를 수집하고 업무를 시작하는 단계에서 사용할만 하지만,    
  신뢰성 있는 모델이라면 확률 기반 샘플링을 사용해야 함.  

  - '확률 기반 샘플링'.  
    - 단순 무작위 샘플링:
      모집단의 각 샘플이 선택될 확률이 모두 동일.  
      예를 들어 모집단의 10%를 무작위로 선태갛면 해당 모집단의 각 구성요소가 선택될 확률은 모두 10%로 동일.  
      단순 무작위 샘플링은 구현이 쉽지만, 단점이 드물게 발생하는 범주의 데이터가 포함되지 않을 수 있다는 점.   
      특정 클래스가 데이터 모집단의 0.01%로 발생한다고 생각했을 때, 데이터 1%를 무작위로 선택하면    
      위와 같이 드물게 발생하는 클래스의 샘플은 포함되지 않음    

    - 계층적 샘플링(Staratified sampling):
    모집단을 상이한 성질의 그룹으로 나눈 뒤 각 그룹에 개별적으로 샘플링을 수행해 단순 무작위 샘플링의 단점을 극복함.  
    ex] 두 클래스 A, B가 있을 때 데이터에서 1%를 샘플링하면, 클래스 A에서 1%, 클래스 B에서 1%를 각각 샘플링함  
    이렇게 하면 클래스 A,B 가 드물게 발생해도 해당 클래스의 샘플이 포함됨  
    각 그룹을 계층(STRATUM) 이라고 하고, 이러한 방법을 계층적 샘플링이라고 함  
    그러나 계층적 샘플링은 항상 가능하지 않는 단점이 있음. 모든 샘플이 원하는 그룹으로 나누는 일 자체가 불가능할 수 있는데,    
    예를 들어 다중 레이블 작업처럼 한 샘플이 여러 그룹에 속한다면 특히 까다로움.(어떤 샘플은 클래스 A와 클래스 B 양쪽에 속함)   

    - 가중 샘플링(weighted sampling):   
    각 샘플에 가중치가 있고, 이를 기반으로 샘플이 선택될 확률이 결정됨.   
    샘 A,B,C가 있고 각가 50%,30%,20% 확룰로 선택될길 원하면 가중치를 0.5, 0.3, 0.2로 정함   
    보유하고 있는 데이터가 실제 데이터 모집단과 다소 다른 분포에서 추출ㄷ괸 경우에 도움이 됨  


    Ex] 보유 데이터 샘플이 빨간색이 25% 이고 파란색이 75%인데, 실제로 데이터 모집단은 빨간색과 파란색이 발생할 확률이 동일하다면   
    빨간색 샘플이 파란색 샘플보다 3배 높은 가중치를 부여함   

    python에서 가중 샘플링은 다음과 같이 random.choices로 구현  

    ```
    # 1,2,3,4는 각각 20% 확룰로, 100, 1000은 각각 10% 확룰로,
    # 리스트에서 아이템 두 개를 선택합니다.
    import random
    random.choices(population=[1, 2, 3, 4, 100, 1000],
                   weights=[0.2, 0.2, 0.2, 0.2, 0.1, 0.1],
                   k=2)

    # 이는 다음 구문의 결과와 같습니다
    random.choices(population = [1, 1, 2, 2, 3, 3, 4, 4, 100, 1000],
                  k=2)
    ```


- 가중 샘플링과 밀접하게 관련된 ML 개념은 '샘플 가중치(sample weight)'임.    
  가중 샘플링은 모델을 훈련할 샘플을 선택하는데 사용하는 반면, 샘플 가중치는 훈련 샘플에 '가중치' 또는 '중요도'를   
  할당하는데 사용   
  샘플 가중치를 변경하면 모델의 결정 경게가 크게 변함  

  - 저수지 샘플링(reservoir sampling):
    프로덕션 환경의 스트리밍 데이터를 처리할 때 유용한 알고리즘   

    지속적으로 수집되는 트윗 스트림이 있고, 분석을 하거나 모델을 훈련하기 위해 k개의 트윗을 샘플링한다고 가정할 때,    
    특정 트윗이 선택될 확률을 미리 알 수 없는데 '각 트윗이 선택될 확률이 동일' 하고 '알고리즘 가동을 언제든지 멈출 수 있으며    
    각 트윗이 올바른 확률로 샘플링됐음을 보장' 해야 한다면?    

    => '저수지 샘플링' 으로, 배열 형태로 구현 가능한 저장소(reservoir)를 포함하여 3단계로 이뤄짐   
    (1) 첫 k개의 요소를 저장소에 넣음    
    (2) 수집되는 각 n 번째 요소마다 1<=i <=n을 만족하는 난수 i 생성   
    (3) 1<=i<=k 라면 저장소의 i번째 요소를 n번째 요소로 교체함   
    아니라면 다음 요소로 넘어감   

    수집되는 각 n번째 요소가 저장소에 포함될 확률이 k/n 이며,    
    저장소 내 각요소가 k/n의 확률로 선택되어, 각 샘플이 선택될 확률이 동일함    



  - 중요도 샘플링(importance sampling)   
    ML뿐 아니라 다양한 분야에 두루 사용되는 중요한 방법   
    이 방법을 사용하면 원하는 분포가 아닌 다른 확률 분포만 활용 가능한 상황에서도    
    원하는 확률 분포에서 샘플링을 수행할 수 있음   


    확률 분포 P(x) 에서 x를 샘플링해야 하는데 P(x)는 샘플링 비용이 크고 느리며 활용이 어려운데,     
    분포 Q(x)는 샘플링하기가 쉽다면 X를 Q(x) 에서 대신 샘플링하고, 해당 샘플의 가중 치를 P(x)/Q(x)로 부여함.    

    Q(X)를 제안 분포(proposal distribution) 또는 중요도 분포(importance distribution) 이라고 부름.     

    Q(x)는 P(x) != 0인 경우 Q(X) > 0을 만족하는 임의의 분포로 정함    



    ML 에서 중요도 샘플링을 사용하는 사례는 정책 기반 강화 학습(policy-based reinforcement learning)임.    
    정책을 업데이트 하는 경우, 새로운 정책의 가치 함수를 추정하고 싶지만 행동에 따르는 총 보상을 계산하는 일은     
    비용이 크기 때문에(행동 후 정해진 시간만큼 기다리고 발생 가능한 결과를 모두 고려해야 하므로),     
    새로운 정책이 이전 정책과 유사하다면 이전 정책을 기반으로 총 보상을 계산하고 새로운 정책에 따른 가중치로 재조정하여, 이전 정책의 보상으로 제안 분포를 구성함




## <4.2 레이블링>   


