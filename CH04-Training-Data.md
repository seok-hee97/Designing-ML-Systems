# [CH04 훈련 데이터(Training Data)]

- 양질의 훈련 데이터를 얻거나 생성하는 기술    
- 여기서의 훈련 데이터는 ML 모델 개발 단계에서 사용하는 데이터를 모두 폴괄하며, 훈련/검증/테스트 목적으로 다양하게 분할한 데이터가 포함됨.   


- '훈련 데이터 셋'이 아닌 '훈련 데이터'라는 용어를 사용하는데, '데이터셋'은 유한하고 고정적인 집합을    
  의미하지만 프로덕션 환겨의 데이터는 유한하지도 고정적이지도 않기 때문

- 데이터는 잠재적인 편향으로 가득하다. 수집, 샘플링, 레이블링 과정에서 발생하기도 하고 과거 데이터는 사람의   
  편향을 내포할 수 있어 해당 데이터로 훈련한 ML 모델은 편향이 공고해질 수 있음.    



## <4.1 샘플링>  

- 샘플링은 매우 다양하게 사용되지만, 한가지로 가용된 전체 실데이터에 접근하기 어려운 경우,    
  모델 훈련을 위해 샘플림으로 실제 데이터의 하위 집합을 생성해 사용   
  또한 접근 권한이 있는 전체 데이터를 다루려면 시간과 자원이 너무 소모되어 데이터를 샘플링해 처리가능한 하위집합을 생성   

- 샘플링 방법을 알면 잠재적인 샘플링 편향을 피할 수 있고, 데이터의 효율성을 향상하는 샘플링 방법을 선택할 수 있다.    

- 샘플링은 크게 '비확률적 샘플링'과 '무작위 샘플링'으로 나뉨     

  - '비확률 샘플링'  
    데이터를 확률이 아닌 기준에 의거해 선택함  
  - 편의 샘플링(Convenience sampling)    
    데이터 샘플을 가용성에 의거해 선택  
  - 눈덩이 샘플링(Snowball sampling)   
    기존 샘플을 기반으로 미래샘플 선택  
    Ex] 트위터 데이터베이스에 접근하지 않고, 트위터 계정을 합법적으로 스크랩하려면 사용자 계정    
    몇 개를  임믜로 만들어 해당 계정을 팔로우하는 계정을 스크랩.  

  - 판단 샘플링(Judgement sampling)  
    전문가가 어떤 샘플을 포함할지 결정   
  - 할당 샘플링(Quota sampling)  
    무작위화(randomization) 없이 특정 데이터 그룹별 할당량에 의거해 샘플 선택.   
    Ex] 실제 연량 분포와 상관없이 설문 조사 실시시 각 연령 그룹(30세 미안,30-60세,60세 초과)마다 응답 100개씩 수집.   


- 확률이 아닌 기준으로 선택한 샘플을 실데이터를 잘 대표하지 못하고 '선택 편향'이 강함   


- ML 훈련을 위한 데이터를 선택할 때 비확률 샘플링을 사용하면 결과과 좋지 않지만 사용이 편리해서 이러한 방법을 많이 사용함.   

  Ex] 언어 모델은 수집하기 쉬운 데이터, 위키백과,커먼 크롤, 레딧 등의 데이터로 훈련하는 경우가 많은ㄷ, 가용한 전체 텍스트를 대표하지 못함.   


  일반 텍스트의 감성 분석을 위한 데이터 또한 imdb 리뷰, 아마존 리뷰 등 자연 레이블(순위)이 있는 소스에서 수집되 다른 감성 분석 작업에 적용됨.   
  그러나 이 리뷰는 온라인 리뷰를 남기는 사용자 집단에 편향되어 있고, 인터넷을 사용하지 못하거나 온라인 리뷰를 남길 의사가 없는 사람까지 대표하기 어려움.  


  또, 자율 주행 자동차 훈련 데이터는 초창기에 애리조나주 피닉스와 캘리포니아주 실리콘 밸리인 날씨가 화창한 지역에서 주로 수집했음.    
  웨이모는 우천 데이터를 확보하고나 비가 많이 오는 워싱턴주의 커클랜드로 사업을 확장했지만 여전히 비나 눈이 내리는 날씨보다 맑은 데이터가 훨씬 많음.   


- 비확룰 샘플링은 빠르고 편해 프로젝트 초창기에 데이터를 수집하고 업무를 시작하는 단계에서 사용할만 하지만,    
  신뢰성 있는 모델이라면 확률 기반 샘플링을 사용해야 함.  

  - '확률 기반 샘플링'.  
    - 단순 무작위 샘플링:
      모집단의 각 샘플이 선택될 확률이 모두 동일.  
      예를 들어 모집단의 10%를 무작위로 선태갛면 해당 모집단의 각 구성요소가 선택될 확률은 모두 10%로 동일.  
      단순 무작위 샘플링은 구현이 쉽지만, 단점이 드물게 발생하는 범주의 데이터가 포함되지 않을 수 있다는 점.   
      특정 클래스가 데이터 모집단의 0.01%로 발생한다고 생각했을 때, 데이터 1%를 무작위로 선택하면    
      위와 같이 드물게 발생하는 클래스의 샘플은 포함되지 않음    

    - 계층적 샘플링(Staratified sampling):
    모집단을 상이한 성질의 그룹으로 나눈 뒤 각 그룹에 개별적으로 샘플링을 수행해 단순 무작위 샘플링의 단점을 극복함.  
    ex] 두 클래스 A, B가 있을 때 데이터에서 1%를 샘플링하면, 클래스 A에서 1%, 클래스 B에서 1%를 각각 샘플링함  
    이렇게 하면 클래스 A,B 가 드물게 발생해도 해당 클래스의 샘플이 포함됨  
    각 그룹을 계층(STRATUM) 이라고 하고, 이러한 방법을 계층적 샘플링이라고 함  
    그러나 계층적 샘플링은 항상 가능하지 않는 단점이 있음. 모든 샘플이 원하는 그룹으로 나누는 일 자체가 불가능할 수 있는데,    
    예를 들어 다중 레이블 작업처럼 한 샘플이 여러 그룹에 속한다면 특히 까다로움.(어떤 샘플은 클래스 A와 클래스 B 양쪽에 속함)   

    - 가중 샘플링(weighted sampling):   
    각 샘플에 가중치가 있고, 이를 기반으로 샘플이 선택될 확률이 결정됨.   
    샘 A,B,C가 있고 각가 50%,30%,20% 확룰로 선택될길 원하면 가중치를 0.5, 0.3, 0.2로 정함   
    보유하고 있는 데이터가 실제 데이터 모집단과 다소 다른 분포에서 추출ㄷ괸 경우에 도움이 됨  


    Ex] 보유 데이터 샘플이 빨간색이 25% 이고 파란색이 75%인데, 실제로 데이터 모집단은 빨간색과 파란색이 발생할 확률이 동일하다면   
    빨간색 샘플이 파란색 샘플보다 3배 높은 가중치를 부여함   

    python에서 가중 샘플링은 다음과 같이 random.choices로 구현  

    ```
    # 1,2,3,4는 각각 20% 확룰로, 100, 1000은 각각 10% 확룰로,
    # 리스트에서 아이템 두 개를 선택합니다.
    import random
    random.choices(population=[1, 2, 3, 4, 100, 1000],
                   weights=[0.2, 0.2, 0.2, 0.2, 0.1, 0.1],
                   k=2)

    # 이는 다음 구문의 결과와 같습니다
    random.choices(population = [1, 1, 2, 2, 3, 3, 4, 4, 100, 1000],
                  k=2)
    ```


- 가중 샘플링과 밀접하게 관련된 ML 개념은 '샘플 가중치(sample weight)'임.    
  가중 샘플링은 모델을 훈련할 샘플을 선택하는데 사용하는 반면, 샘플 가중치는 훈련 샘플에 '가중치' 또는 '중요도'를   
  할당하는데 사용   
  샘플 가중치를 변경하면 모델의 결정 경게가 크게 변함  

  - 저수지 샘플링(reservoir sampling):
    프로덕션 환경의 스트리밍 데이터를 처리할 때 유용한 알고리즘   

    지속적으로 수집되는 트윗 스트림이 있고, 분석을 하거나 모델을 훈련하기 위해 k개의 트윗을 샘플링한다고 가정할 때,    
    특정 트윗이 선택될 확률을 미리 알 수 없는데 '각 트윗이 선택될 확률이 동일' 하고 '알고리즘 가동을 언제든지 멈출 수 있으며    
    각 트윗이 올바른 확률로 샘플링됐음을 보장' 해야 한다면?    

    => '저수지 샘플링' 으로, 배열 형태로 구현 가능한 저장소(reservoir)를 포함하여 3단계로 이뤄짐   
    (1) 첫 k개의 요소를 저장소에 넣음    
    (2) 수집되는 각 n 번째 요소마다 1<=i <=n을 만족하는 난수 i 생성   
    (3) 1<=i<=k 라면 저장소의 i번째 요소를 n번째 요소로 교체함   
    아니라면 다음 요소로 넘어감   

    수집되는 각 n번째 요소가 저장소에 포함될 확률이 k/n 이며,    
    저장소 내 각요소가 k/n의 확률로 선택되어, 각 샘플이 선택될 확률이 동일함    



  - 중요도 샘플링(importance sampling)   
    ML뿐 아니라 다양한 분야에 두루 사용되는 중요한 방법   
    이 방법을 사용하면 원하는 분포가 아닌 다른 확률 분포만 활용 가능한 상황에서도    
    원하는 확률 분포에서 샘플링을 수행할 수 있음   


    확률 분포 P(x) 에서 x를 샘플링해야 하는데 P(x)는 샘플링 비용이 크고 느리며 활용이 어려운데,     
    분포 Q(x)는 샘플링하기가 쉽다면 X를 Q(x) 에서 대신 샘플링하고, 해당 샘플의 가중 치를 P(x)/Q(x)로 부여함.    

    Q(X)를 제안 분포(proposal distribution) 또는 중요도 분포(importance distribution) 이라고 부름.     

    Q(x)는 P(x) != 0인 경우 Q(X) > 0을 만족하는 임의의 분포로 정함    



    ML 에서 중요도 샘플링을 사용하는 사례는 정책 기반 강화 학습(policy-based reinforcement learning)임.    
    정책을 업데이트 하는 경우, 새로운 정책의 가치 함수를 추정하고 싶지만 행동에 따르는 총 보상을 계산하는 일은     
    비용이 크기 때문에(행동 후 정해진 시간만큼 기다리고 발생 가능한 결과를 모두 고려해야 하므로),     
    새로운 정책이 이전 정책과 유사하다면 이전 정책을 기반으로 총 보상을 계산하고 새로운 정책에 따른 가중치로 재조정하여, 이전 정책의 보상으로 제안 분포를 구성함




## <4.2 레이블링>   


- 비지도 ML의 장점에도 프로덕션 환경 내 ML 모델은 대부분 지도 학습 기반이다.   
  학습 용도로 레이블한 데이터가 필요해서, ML 모델의 성능은 여전히 학습 용도로 지정한 데이터의 양과 질에 크게 의존한다.    


#### <래아불 다중성>   
- 서로 다른 데이터 소스와 어노테이터가 지닌 정확도 수준은 상이해서 레이블 모호성,    
  레이블 다중성 문제, 즉 데이터 포인트에 상충하는 레이블이 복수로 존재하는 상황이 야기됨   
- 요구되는 도메인 전문 지식이 높을수록 불일치하게 레이블링 할 가능성이 커짐.   
- 어노테이터 간의 불일치를 최소화하기 위해 먼저 문제를 명확히 정의해야 함.  


#### <데이터 계보>   
- 서로 다른 어노테이터가 생성한 다양한 소스의 데이터를 품질에 대한 고민 없이 사용하면 모델에 알 수 없는 문제가 발생함
 
- 각 데이터 샘플과 레이블의 출처를 추적 가능하도록 설정하는 것을 '데이터 계보(data lineage)' 라고함   
- 데이터 계보는 데이터 내 잠재 편향에 플래그를 할당하고 모델을 디버깅하는데 도움을 줌.  


#### <자연 레이블>   

- 자연적인 그라운드 트루스 레이블이 존재하면 모델 예측을 자동으로 평가하거나 시스템상에서 부분적으로 평가할 수 있음  
  
  예를 들어, 구글 지도에서 특정 경로의 도착 시간을 추정하는 모델과 주가 예측

- 자연 레이블이 존재하는 작업은 대표적으로 추천 시스템으로, 추천 시스템의 목표는 사용자와 연관된 항목을 추천해주는 것임   
  사용자가 추천받은 항목을 클릭하는지 여부가 해당 추천에 대한 '피드백'으로 간주됨   
  클릭한 추천은 적합한 것으로 레이블 양성, 일정 시간이 지나도 클릭하지 않는 추천은 레이블이 음성   

- 많은 작업은 추천 방식으로 구조화할 수 있는데, 광고 클릭률을 예측하는 작업을   
  예로 들면 사용자의 활동 기록과 프로필을 기반으로 가장 연관성 높은 광고를 추천하는 작업으로 구조화하여,    
  클릭과 평점처럼 사용자 행동에서 추론하는 자연 레이블을 행동 레이블(behavioral label) 이라고 함   

- 작업에 자연 레이블이 없더라도 모델에 대한 피드백을 수집하게끔 시스템을 설정하는데, 구글 번역 같은 기계 번역 시스템을 개발하여,   
  사용자 커뮤니티에서 다른 번역을 제출할 수 있는 옵션을 마련하여 제안된 번역의 품질을 검토해 모델의 다음번 반복 학습에 사용한다.   

- 업계에서는 자연 레이블로 작업하는 경우가 흔함

- 위에서 일정 시간이 지나도 클릭하지 않는 추천은 좋지 못한 것으로 간주해서 이러한 음성 레이블은    
  양성 레이블의 부재를 통해 추정하여 '암시적 레이블(implicit label)' 이라고 함
  - 사용자가 추천 항목에 낮은 평점을 부여하거나 거부를 표해서 명시적으로 피드백을 주는 '명시적(explicit label)'



#### <피드백 루프 길이>   
- 자연적인 그라운드 트루스 레이블이 존재하는 작업에서, 예측을 수행하는 시점부터   
  피드백을 얻는 시점까지 걸리는 시간을 '피드백 루프 길이(feedback loop length)'라고 함   

- 피드백을 포착할 윈도 길이(window length)를 적절히 결정하려면 고민이 필요한데,   
  속도와 정확도 사이에 트레이드오프가 있기 때문이다.

- 윈도 길이가 짧으면 레이블을 더 빨리 얻을 수 있고, 레이블을 이용해 모델의 문제를 조기에 발견하고 빠르게 해결할 수 있지만   
  추천을 클릭하기 이전 너무 이른 시점에 사용자가 클릭하지 않아서 레이블을 잘못 지정해줄 수 있음   



#### <레이블 부족 문제 해결>     

- 고품질 레이블을 충분히 얻기는 어려워, 이를 해결하기 위해 약한 지도 학습(weak supervision),   
  준지도 학습(semi-supervision), 전이 학습(transfer learning), 능동적 학습(active learning)   


  - 약한 지도 학습(weak supervision) :   
  레이블을 생성하기 위해 (때때로 잡음이 있는) 휴리스틱 활용. 그라운드 트루스는 필요하지 않지만,   
  휴리스틱 개발의 기준을 삼기 위해 레이블을 적게나마 갖추기를 권장
  - 준지도 학습(semi-supervision) :    
  구조적인 가정을 활용해 레이블을 생성함.     
  그라운드 트루스가 필요하고 레이블을 추가로 생성하기 위한 시드로써 초기에 수집한 레이블이 조금 필요함.   
  - 전이 학습(trnasfer learning):    
  다른 작업에서 사전 훈련한 모델을 새로운 작업에 활용함.   
  제로샷 학습이라면 그라운드 트루스가 필요 없으나, 미세 조정이라면 그라운드 트루스가 필요하다.    
  다만 모델을 밑바닥부터 훈련할 때부터 보통은 훨씬 적게 필요함.   
  - 능동적 학습(active learning) :    
  모델 입장에서 가장 유용한 데이터 샘플을 레이블링하고, 그라운드 트루스가 필요함.   



#### 약한 지도학습(Weak supervision)   

- 수작업 레이블이 문제라면 아예 사용하지 않는 방법도 있음   

- 약한 지도 학습은 데이터를 레이블링할 때 도메인 전문 지식을 통해 개발된 휴리스틱을 활용함   
  예를 들어, 의사가 다른 휴리스틱을 이용해 환자를 위급하다고 판단해 우선시할지 결정함   
  [간호사 노트에 폐렴 같은 심각한 상태가 언급되면 해당 환자를 우선적으로 고려한다]    

- 스노클 같은 라이브러리는 '레이블링 함수(labeling function(LF)' 개념을 기반으로 개발됨    
- LF는 휴리스틱을 인코딩한 함수임    

```
def labeling_function(note):
  if "페렴" in note:
    return "위급"

```

- LF로 다양한 유형의 휴리스틱을 인코딩할 수 있음
  - 키워드 휴리스틱, 정규 표현식, 데이터베이스 조회 ,다른 모델의 출력


- LF를 작성한 후 레이블링하려는 샘플에 적용하는데, LF는 휴리스틱을 인코딩하고,    
  휴리스틱에는 잡음이 존재해서 LF가 생성한 레이블에는 잡음이 수반됨   


한 휴리스틱이 다른 휴리스틱보다 훨씬 정확하더라도 비교할 그라운드 트루스 레이블이 없어 사실을 인지하지 못해서,    
레이블이 올바를 가능성이 높은 집합을 얻으려면 모든 LF를 결합하고 잡음을 제거한 뒤 가중치를 재조정함.   