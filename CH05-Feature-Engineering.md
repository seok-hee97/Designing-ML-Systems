# CH05 Feature Engineering

- 올바른 피처를 보유하는 것은 ML 모델을 개발하는데 중요함
- 실행가능한 모델이 있는 한 올바른 피처를 보유하는 것이 하이퍼파라미터 조정 같은 알고리즘 기법보다 큰 향상을 이끌어낼 수도 있음


## <5.1 학습된 피처 vs 엔지니어링된 피처>

- 딥러닝을 수행하면 피처 엔지니어링이 필요 엔지니어링이 필요 업시도 함.    
  딥러닝의 장점은 피처를 수작업으로 만들 필요가 없어서, 딥러닝의 치퍼 학습이라고도 함     
- 많은 피처들이 알고리즘에 의해 자동으로 학습되고 추출되지만, 모든 피처를 자동화하려면 아직 멀었음   
- 프로덕션용 ML 애플리케인션의 대부분은 딥러닝이 아니기도 함    
  
  for example, 댓글의 스팸 여부를 분류하기 위해 감성 분류기를 구축한다고 가정할 떄, 딥러닝 이전에는   
  텍스트 조각이 주어졌을 때 '표제어 추출(Lemmatization)', '줄임말 확장(expanding contraction)',   
  '구두점(punctuation) 제거', '소문자화(lowercasing)' 와 같은 고전적인 텍스트 처리 기술을   
  수동으로 적용하고,텍스트를 n-gram으로 분할함    


- n-gram은 주어진 텍스트 샘플 내 항목 n개의 연속 시퀀스임    
  항목은 '음소(phoneme)', '음절(syllable)', 문자 또는 단어임   
  예를 들어, 'I like food' 라는 게시물이 주어지면 단어 레벨 1-gram은 ['I', 'like', 'food'],   
  단어 레벨 2-gram은 ['I like', 'like food'] 이다.   
  n이 1과 2 일때 이 문장의 n-gram 피처 집합은 ['I', 'like','food', 'I like', 'like food'] 이다.   

![img](img/fig5-1.png)
  텍스트에 대한 n-gram 피처를 수작업으로 생성하는 텍스트 처리 기법은   
  (1) 원본 텍스트 -> (2) 불용어 제거 -> (3) 표제어 추출 -> (4) 줄임말 확장   
  -> (5) 구두점 제거 -> (6) 소문화 -> (7) 토큰화 -> (8) N-gram   

  훈련 데이터에 대한 n-gram을 생성한 뒤에는 각 n-gram을 인덱스에 매핑하는 어휘(vocabulary)를 생성하여,   
  n-gram의 인덱스 기반으로 벡토로 변환함.    

  n-gram의 어휘가 7이면 각 게시물은 요소 7개로 구성된 벡터가 되며,    
  각 요소는 해당 인덱스의 n-gram이 게시물에 나타나는 횟수에 해당함    

  I->0, like->1, good->2, food->3, I like 4 ->, good food->5, like food->6    
  'I like food'는 벡터 [1,1,0,1,1,0,1] 로 인코딩 됨    

  피처 엔지니어링에는 도메입녈 기술에 대한 지식이 필요함.
  도메인은 자연어 처리이고, 텍스트 언어는 영어임

- 피처 엔지니어링은 프로세스는 반복적인 경향이 있어, 따라서 취약할 수 있음.   

- 위에 있는 자연어처리 시 표제어, 구두점 또는 불용어(stopword) 제거를 신경 쓸 필요 없이 원시 텍스트를 단어로 분할(토큰화: tokenization)하고,    
  단어로 어휘를 만들고 이를 사용개 각 단어를 원-핫 벡터로 변환하여, 모델이 이러부터 유용한 피처를 추출하는 것을 학습함    


- ML 시스템에 텍스트와 이미지 외의 데이터가 필요한 경우가 있는데, 예뜰 들면 댓글의 스팸 여부를 감지 할 때는     
  댓글 텍스트 왜에 댓글의 수(찬성과 반대가 각각 몇 개 인지),  
  댓글을 게시한 사용자(계정이 언제 생성됐고 얼마나 자주 게시하면 찬성과 반대를 얼마나 많이 얻었는지),     
  댓글이 게시된 스레드(조회수가 몇인지, 인기 있는 스레들일수록 스팸성 댓글이 많은 경향이 있음)    


- 피처 엔지니어링은 사용할 정보를 선택하고 이 정보를 ML 모델에서 사용하는 포맷으로 추출하는 프로세스임   


## <5.2 피처 엔지니어링 기법>   

- 데이터의 피처를 전처리 할때 고려할 중요한 작업은   
  결측값(missing value) 처리, 스케일링(scaling), 이산화(discretization),    
  범주형(categorical) 피처 인코딩, 교차(cross) 피처와 위치(positional) 피처 생성 등이 있음     


##### [결측값 처리]

- 결측값에는 세가지 유형
  - (1) 비무작위결측(MNAR, Missing not at random): 결측값이 발생한 이유가 실제 값 자체에 있음   
    for exmaple, 일부 응답자가 소득을 공개하지 않았을 때, 소득을 신고하지 않은 응답자가 소득을 신고한   
    응답자보다 소득이 더 높은 경향이 있다고 판명 될 수 있는 것처럼, 소득 값이 누락된 이유는 '값 자체와 관련됨'  

  - (2) 무작위결측(MAR, Missing at Random): 결측값이 발생한 이유가 값 자체가 아닌 다른 관측 변수에 있음    

    예시에서 성별이 'A'인 응답자가의 연령 값이 누락된 경우가 있는데, 설문 조사에서 성별이 'A'인 응답자가   
    연령 공개를 원하지 않아서 일 수도 있음    


  - (3) 완전 무작위 결측(MCAR, Missing completey at random): 결측값에 패턴이 없음   
    for example, '직업' 열의 결측값은 값이나 다른 변수들 때문이 아니라 완전 무작위임.    
    사람들은 때때로 특별한 이유 없이 값을 채우는 것을 잃어버리는데,  
    이러한 결측은 매우 드물며 보통 값이 누락되는 데는 이유가 있어 조사가 필요함.    

- 결측값은 특정 값으로 채우거나(대치), 제거(삭제)해 처리함    



##### [결측값 삭제(Deletion)]

- 결측값 처리에서 삭제는 '열 삭제'와 '행 삭제' 방법이 있음.  

- 행 삭제는 누락된 값(들)이 있는 샘플을 제거함.  
  : 이 방법은 결측값이 완전 무작위(MCAR) 이며, 결측값 있는 샘플의 비주이 적을 때(예를 들어 0.1%) 유용함.   
  (데이터 샘플의 10%를 제거할 수 없으므로).   

  데이터 행을 제거하면, 결측값이 비무작위(MNAR)의 경우, 모델이 수행하는데  필요한 중요한 정보고 제거될 수 있음    
  데이터 행을 제거하면 결측값이 무작위(MAR)인 경우 모델에 편향이 발생할 수 있음    



##### [결측값 대치(Imputastion)].   

- 데이터 삭제가 더 쉽긴 하지만 중요한 정보가 손실되고 모델에 편향이 발생할 수 있는 단점이 있으므로,   
  결측값을 삭제하는 대신 특정 값으로 채우는 방법이 있음.   

- 결측값을 대치할 때는 일반적으로 기본값으로 채움
  예를 들어, 작업이 누락된 경우 빈 문자열 ''로 채우거나, 결측값을 평균 mean, 중앙값 median,  
  최빈값 mode 로 채우는 일밙거인 방법도 있음    

- 결측값 삭제와 대치 모두 많은 경우에 잘 작동하지만 문제가 있는 사용자 경험을 유발할 수 도 있음

- 일반적으로 결측값을 가능한 값으로 채우지 않는 편이 좋음
  예를 들어 자녀 수 피처의 결측값을 0으로 채우지 않는 것이 좋은데, 값이 0일수도 있기 때문임.   
  결측값을 0으로 채우면 정보가 없는 사람과 자녀가 없는 사람을 구분하기가 어려워짐    

- 특정 데이터셋에 대한 결측값을 처리하기 위해 여러 기법을 동시에 또는 순서대로 사용할 수 있음   
  

- 결측값을 삭제하면 중요한 정보를 잃거나 편향이 강조될 위험이 있고,    
  결측값 대치를 사용하면 데이터에 자신의 편향을 중립하고 데이터에 잡음을 더할 수 있음.    
  심한 경우 데이터 누수 위험이 있음    




##### [스케일링]     

- 예를 들어 12개월 내 주택 구매 여부를 예측하는 작업을 진행할 때, 데이터 연령 변수는 20-40 인 반면,    
  연간 소득 변수는 10,000-150,000 사이임. 두 변수를 ML 모델에 입력하면 모델은 150,000와 40이    
  서로 다른 것을 나타낸 다는 사실을 이해하지 못함    
- 모델이 피처를 입력하기 전에 각 피처를 유사한 범위로 스케일링 하는 것이 중요함 => 피처 스케일링
- 적은 노력으로 모델 성능 향샹을 이끌어 낼 수 있고, 이 작업을 하지 않으면 모델이 이상한 예측을 할 수 있음    
  (그래디언트 부스트 트리나 로지스틱 회구 같은 경우)

- 직관적으로 피처를 스케일링 하려면 [0,1] 범위로 조절함    
  변수 x가 주어졌을 때, 공식적으로 변수 값이 [0,1] 범위에 있도록 조절함    


x' = x-min(x) / max(x) -min(x)    
x가 최대값이면 스케일링된 값 x'가 1이고 x가 최소값이면 스케일링된 값 x'는 0   
피처의 임의의 범위 [a,b]에 있도록 하려면 다음의 공식을 사용하는데 [-1, 1] 범위가 [0,1] 범위보다 더 잘 동작함   

```
x' = a + (x-min(x))(b-a) / max(x) - min(x)
```

- 임의의 범위로 스케일링 하는 것은 변수에 대해 아무런 분포 가정을 하지 않을 때도 효과적임    

- 변수가 정규 분표를 따른다고 생각하면 평균고 단위 분산 (unit varinacE)가 0이 되도록 정규화하면 됨   
  => 표준화(standardzation)    
  x' = x-x bar / σ   

- 실제로 ML 모델은 비대칭 분포를 따르는 피처로 어려움을 겪는 경향이 있음    
  왜곡을 완화하는 기법으로 피처에 '로그 변환(log transformation)'을 적용함 => 데이터 왜곡을 줄임   
  로그 변환으로 성능이 향상될 때가 많지만 모든 경우에 작동하지는 않음    
  실젯값이 아닌 로그 변환된 피처 값으로 분석하지 않도록 주의해야함     


- 스케일링은 데이터 누수의 원인이 될 수 있고, 전역 통계치가 필요한 경우가 많음.    
  최소, 최대 또는 평균을 계산하려면 전체 훈련 데이터 또는 부분 집합을 확인해야 함     
  => 추론하는 동안 훈련 중에 얻은 통계치를 재사용해 신규 데이터를 스케일링할 수 있는데,     
  신규 데이터가 훈련 데이터의 통게에서 크게 변경됐다면 훈련 데이터 통계는 유용하지 않기 때문에     
  모델을 자주 재훈련하는 것이 중요함     


##### [이산화]    

- 실제로 이산화가 도움이 되는 경우는 거의 없음    

- 이산화는 연속형 피처를 불연속형 피처로 바꾸는 과정임    

- 양자화(quantization) 또는 비닝(binning)이라고 하며, 주어진 값에 대한 버킷을 생성함    

- 양자화를 적용하면 모델은 무한한 범주에 대해 훈련할 필요 없이 훨씬 훈련하기 쉬운 범주로 훈련하는데 집중할 수 있고,   
  이 기법은 훈련 데이터가 제한된 경우에 더 유용함   


- 이산화는 연속형 피처 뿐 아니라 이산현 피처에도 적용이 가능함   

- 단점은 범주 분류가 범주 경계에서 불연속성을 발생시킨다는 것임    
  예를 들어, $100,000는 $35,000와 동일하게 처리되는 반면,   
  훨씬 가까운 값인 $34,999는 완전히 다른 값으로 처리됨     

- 범주의 경계를 선택하기는 쉽지 않은데, 변숫값의 히스토그램을 확인하고 적절한 경계를 선택해야 일반적으로 상식,    
  기본 분위수, 주제 전문 지식이여도 도움이 됨


##### [범주형 피처 인코딩]    

- 프로덕션 데이터 경험이 없는 사람들은 범주가 '정적'이라고 가정하는 경향이 있는데,     
  실제로 많은 범주는 '정적'이긴 함   
  예를 들어, 연령 버킷과 소득 버킷은 거의 변하지 않고 범주가 정확히 몇 개 인지 미리 알고 있어   
  이러한 범주는 각각의 번호만 부여하면 됨   

- 그러나 프로덕션에서는 범주가 변화함    
  사용자가 아마존에서 구매할 제품을 예측하는 추천 시스템을 구축한다고 가정했을 때,     
  '제품 브랜드' 피처는 아마존에서 2019년에 이미 200만개를 넘겼음    

  브랜드가 압도적으로 많지만, 각 브랜드를 숫자로 인코딩하면 200만 개 브랜드   
  각각이 0부터 1,999,999까지 200만 개 수치로 변환됨    
  모델은 과거 테스트 세트에서 매우 잘 수행되기에, 현재 트래픽의 1%에서 테스트하도록 승인됐다고 가정을 함  
  하지만 프로덕션에서는 모델이 문제를 일으키게 되는데, 본 적이 없는 브랜드를 발견하면 인코딩을 할 수 없게 됨 
  프로덕션에서는 지속적으로 신규 브랜드가 입점하기 때문에, 이 문제를 해결하기 위해서는 2,000,000인   
  UNKNOWN 범주로 새 브랜드를 할당해야 함   
  그러나, 모델이 훈련 세트에서 UNKNOWN 카테고리를 보지 못했으므로   
  UNKNOWN 브랜드 제품을 추천하지 않게 됨    
  => 이 경우, 가장 인기 있는 상위 99% 브랜드만 인코딩하고 하위 1% 브랜드를 UNKNOWN으로 인코딩함    
  약 1시간은 모델이 제대로 작동하지만, 제품 추천에 대한 클릭률이 곤두박질 침    
  => 1시간 동안 신규 브랜드 20개가 입점함    
  일부는 신규 명품 브랜드이고 일부는 모조고 일부는 기성 브랜드임    
  그러나, 모델은 모두 훈련 데이터에서 인기가 없는 브랜드와 동일하게 취급함   


- 위와 같은 상황은 여러 사례에서 많이 발생함    
  예를 들어, 댓글의 스팸 여부를 예측하는 사례에서 댓글을 게시한 계정을 피처로 사용할 수 있는데,     
  신규 계정은 계속해서 생성되고 신규 제품 유형, 신규 웹사이트 도메인, 신규 IP 주소 등 마찬가지이다.    
  모두 신규 범주가 추가될 때 발생하기 시작함     

  => 위의 문제를 해결하는 방법은 의외로 찾기 어려움    
  신규 범주에 적절한 버킷을 할당하는 것이 어렵기 때문임     

  
